import unittest
import numpy as np
import time
import psutil
import sys
import os
from typing import Dict, List, Any, Tuple
import json
import threading
import multiprocessing

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from config.training_config import TrainingConfig
from config.model_config import ModelConfig
from training.hierarchical_trainer import HierarchicalTrainer
from environment.multi_scale_env import MultiScaleEnvironment
from data_processing.scenario_generator import ScenarioGenerator, ScenarioType

class ScalabilityTest(unittest.TestCase):
    """å¯æ‰©å±•æ€§æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•è®¾ç½®"""
        self.results = {}
        self.scenario_generator = ScenarioGenerator()
        
        # è·å–ç³»ç»Ÿä¿¡æ¯
        self.cpu_count = os.cpu_count()
        self.memory_gb = psutil.virtual_memory().total / (1024**3)
        
        print(f"ç³»ç»Ÿä¿¡æ¯: {self.cpu_count} CPUs, {self.memory_gb:.1f}GB RAM")
    
    def test_battery_count_scalability(self):
        """ç”µæ± æ•°é‡å¯æ‰©å±•æ€§æµ‹è¯•"""
        print("ğŸ”‹ å¼€å§‹ç”µæ± æ•°é‡å¯æ‰©å±•æ€§æµ‹è¯•")
        
        # ä¸åŒçš„ç”µæ± æ•°é‡é…ç½®
        battery_counts = [1, 3, 5, 10, 20]
        scalability_results = {}
        
        for num_batteries in battery_counts:
            print(f"æµ‹è¯• {num_batteries} ä¸ªç”µæ± ")
            
            start_time = time.time()
            memory_before = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            
            try:
                # è°ƒæ•´é…ç½®ä»¥é€‚åº”ç”µæ± æ•°é‡
                training_config = TrainingConfig()
                training_config.upper_config.total_episodes = 10
                training_config.lower_config.total_episodes = 10
                
                model_config = ModelConfig()
                # è°ƒæ•´ä¸‹å±‚åŠ¨ä½œç»´åº¦ä»¥é€‚åº”ç”µæ± æ•°é‡
                model_config.lower_layer.action_dim = num_batteries * 2  # æ¯ä¸ªç”µæ± 2ä¸ªæ§åˆ¶ç»´åº¦
                model_config.lower_layer.state_dim = num_batteries * 4   # æ¯ä¸ªç”µæ± 4ä¸ªçŠ¶æ€ç»´åº¦
                
                # åˆ›å»ºåœºæ™¯
                scenario = self.scenario_generator.generate_scenario(
                    scenario_type=ScenarioType.DAILY_CYCLE,
                    scenario_id=f"scalability_battery_{num_batteries}"
                )
                
                # åˆ›å»ºç¯å¢ƒ
                env = MultiScaleEnvironment(
                    scenario=scenario,
                    config=training_config.environment_config
                )
                
                # åˆ›å»ºè®­ç»ƒå™¨
                trainer = HierarchicalTrainer(
                    config=training_config,
                    model_config=model_config,
                    trainer_id=f"scalability_trainer_{num_batteries}"
                )
                
                # æ‰§è¡Œç®€åŒ–è®­ç»ƒ
                training_result = trainer.train(
                    environment=env,
                    num_episodes=10
                )
                
                # æµ‹é‡æ€§èƒ½
                execution_time = time.time() - start_time
                memory_after = psutil.Process().memory_info().rss / 1024 / 1024  # MB
                memory_usage = memory_after - memory_before
                
                # è®¡ç®—ååé‡
                total_steps = 10 * 100  # å‡è®¾æ¯å›åˆ100æ­¥
                throughput = total_steps / execution_time
                
                scalability_results[num_batteries] = {
                    'execution_time': execution_time,
                    'memory_usage_mb': memory_usage,
                    'throughput_steps_per_sec': throughput,
                    'memory_per_battery_mb': memory_usage / num_batteries,
                    'time_per_battery_sec': execution_time / num_batteries,
                    'success': True
                }
                
                print(f"  æˆåŠŸ - æ—¶é—´: {execution_time:.2f}s, å†…å­˜: {memory_usage:.1f}MB")
                
            except Exception as e:
                print(f"  å¤±è´¥ - {str(e)}")
                scalability_results[num_batteries] = {
                    'execution_time': time.time() - start_time,
                    'memory_usage_mb': 0,
                    'throughput_steps_per_sec': 0,
                    'memory_per_battery_mb': 0,
                    'time_per_battery_sec': 0,
                    'success': False,
                    'error': str(e)
                }
        
        # åˆ†æå¯æ‰©å±•æ€§
        scalability_analysis = self._analyze_battery_scalability(scalability_results)
        
        # ä¿å­˜ç»“æœ
        self.results['battery_count_scalability'] = {
            'results': scalability_results,
            'analysis': scalability_analysis
        }
        
        print("âœ… ç”µæ± æ•°é‡å¯æ‰©å±•æ€§æµ‹è¯•å®Œæˆ")
        self._print_battery_scalability_results(scalability_results, scalability_analysis)
    
    def test_episode_count_scalability(self):
        """è®­ç»ƒå›åˆæ•°å¯æ‰©å±•æ€§æµ‹è¯•"""
        print("ğŸ“ˆ å¼€å§‹è®­ç»ƒå›åˆæ•°å¯æ‰©å±•æ€§æµ‹è¯•")
        
        episode_counts = [10, 50, 100, 200, 500]
        episode_scalability_results = {}
        
        for num_episodes in episode_counts:
            print(f"æµ‹è¯• {num_episodes} ä¸ªè®­ç»ƒå›åˆ")
            
            start_time = time.time()
            memory_before = psutil.Process().memory_info().rss / 1024 / 1024
            
            try:
                # æ ‡å‡†é…ç½®
                training_config = TrainingConfig()
                training_config.upper_config.total_episodes = num_episodes
                training_config.lower_config.total_episodes = num_episodes
                
                model_config = ModelConfig()
                model_config.upper_layer.hidden_size = 64  # è¾ƒå°çš„ç½‘ç»œä»¥åŠ é€Ÿæµ‹è¯•
                model_config.lower_layer.hidden_size = 64
                
                # åˆ›å»ºåœºæ™¯
                scenario = self.scenario_generator.generate_scenario(
                    scenario_type=ScenarioType.DAILY_CYCLE,
                    scenario_id=f"scalability_episode_{num_episodes}"
                )
                
                # åˆ›å»ºç¯å¢ƒ
                env = MultiScaleEnvironment(
                    scenario=scenario,
                    config=training_config.environment_config
                )
                
                # åˆ›å»ºè®­ç»ƒå™¨
                trainer = HierarchicalTrainer(
                    config=training_config,
                    model_config=model_config,
                    trainer_id=f"episode_scalability_trainer_{num_episodes}"
                )
                
                # ç›‘æ§èµ„æºä½¿ç”¨
                resource_monitor = ResourceMonitor()
                resource_monitor.start()
                
                # æ‰§è¡Œè®­ç»ƒ
                training_result = trainer.train(
                    environment=env,
                    num_episodes=min(num_episodes, 100)  # é™åˆ¶å®é™…æ‰§è¡Œçš„å›åˆæ•°ä»¥æ§åˆ¶æµ‹è¯•æ—¶é—´
                )
                
                # åœæ­¢ç›‘æ§
                resource_monitor.stop()
                
                execution_time = time.time() - start_time
                memory_after = psutil.Process().memory_info().rss / 1024 / 1024
                memory_usage = memory_after - memory_before
                
                # è·å–èµ„æºä½¿ç”¨ç»Ÿè®¡
                cpu_stats = resource_monitor.get_cpu_stats()
                memory_stats = resource_monitor.get_memory_stats()
                
                episode_scalability_results[num_episodes] = {
                    'execution_time': execution_time,
                    'memory_usage_mb': memory_usage,
                    'episodes_per_second': min(num_episodes, 100) / execution_time,
                    'avg_cpu_percent': cpu_stats['avg_cpu_percent'],
                    'max_cpu_percent': cpu_stats['max_cpu_percent'],
                    'avg_memory_mb': memory_stats['avg_memory_mb'],
                    'max_memory_mb': memory_stats['max_memory_mb'],
                    'success': True
                }
                
                print(f"  å®Œæˆ - æ—¶é—´: {execution_time:.2f}s, CPU: {cpu_stats['avg_cpu_percent']:.1f}%")
                
            except Exception as e:
                print(f"  å¤±è´¥ - {str(e)}")
                episode_scalability_results[num_episodes] = {
                    'execution_time': time.time() - start_time,
                    'success': False,
                    'error': str(e)
                }
        
        # ä¿å­˜ç»“æœ
        self.results['episode_count_scalability'] = episode_scalability_results
        
        print("âœ… è®­ç»ƒå›åˆæ•°å¯æ‰©å±•æ€§æµ‹è¯•å®Œæˆ")
        self._print_episode_scalability_results(episode_scalability_results)
    
    def test_parallel_processing_scalability(self):
        """å¹¶è¡Œå¤„ç†å¯æ‰©å±•æ€§æµ‹è¯•"""
        print("âš¡ å¼€å§‹å¹¶è¡Œå¤„ç†å¯æ‰©å±•æ€§æµ‹è¯•")
        
        # æµ‹è¯•ä¸åŒçš„å¹¶è¡Œåº¦
        worker_counts = [1, 2, 4, min(8, self.cpu_count)]
        parallel_results = {}
        
        for num_workers in worker_counts:
            print(f"æµ‹è¯• {num_workers} ä¸ªå¹¶è¡Œworker")
            
            start_time = time.time()
            
            try:
                # åˆ›å»ºå¤šä¸ªç‹¬ç«‹çš„è®­ç»ƒä»»åŠ¡
                training_tasks = []
                
                for worker_id in range(num_workers):
                    task = self._create_training_task(
                        task_id=f"parallel_task_{worker_id}",
                        episodes=20
                    )
                    training_tasks.append(task)
                
                # å¹¶è¡Œæ‰§è¡Œè®­ç»ƒä»»åŠ¡
                if num_workers == 1:
                    # ä¸²è¡Œæ‰§è¡Œ
                    results = [self._execute_training_task(task) for task in training_tasks]
                else:
                    # å¹¶è¡Œæ‰§è¡Œ
                    with multiprocessing.Pool(processes=num_workers) as pool:
                        results = pool.map(self._execute_training_task, training_tasks)
                
                execution_time = time.time() - start_time
                
                # èšåˆç»“æœ
                successful_tasks = [r for r in results if r['success']]
                total_episodes = sum(r['episodes_completed'] for r in successful_tasks)
                avg_performance = np.mean([r['final_performance'] for r in successful_tasks]) if successful_tasks else 0
                
                parallel_results[num_workers] = {
                    'execution_time': execution_time,
                    'successful_tasks': len(successful_tasks),
                    'total_tasks': len(training_tasks),
                    'total_episodes': total_episodes,
                    'episodes_per_second': total_episodes / execution_time,
                    'avg_performance': avg_performance,
                    'speedup': parallel_results[1]['execution_time'] / execution_time if 1 in parallel_results else 1.0,
                    'efficiency': (parallel_results[1]['execution_time'] / execution_time) / num_workers if 1 in parallel_results else 1.0,
                    'success': True
                }
                
                print(f"  å®Œæˆ - æ—¶é—´: {execution_time:.2f}s, æˆåŠŸç‡: {len(successful_tasks)}/{len(training_tasks)}")
                
            except Exception as e:
                print(f"  å¤±è´¥ - {str(e)}")
                parallel_results[num_workers] = {
                    'execution_time': time.time() - start_time,
                    'success': False,
                    'error': str(e)
                }
        
        # ä¿å­˜ç»“æœ
        self.results['parallel_processing_scalability'] = parallel_results
        
        print("âœ… å¹¶è¡Œå¤„ç†å¯æ‰©å±•æ€§æµ‹è¯•å®Œæˆ")
        self._print_parallel_scalability_results(parallel_results)
    
    def test_memory_scalability_limits(self):
        """å†…å­˜å¯æ‰©å±•æ€§æé™æµ‹è¯•"""
        print("ğŸ§  å¼€å§‹å†…å­˜å¯æ‰©å±•æ€§æé™æµ‹è¯•")
        
        # é€æ­¥å¢åŠ æ¨¡å‹å¤§å°ç›´åˆ°å†…å­˜é™åˆ¶
        hidden_sizes = [64, 128, 256, 512, 1024, 2048]
        memory_limit_results = {}
        
        for hidden_size in hidden_sizes:
            print(f"æµ‹è¯•éšè—å±‚å¤§å°: {hidden_size}")
            
            memory_before = psutil.Process().memory_info().rss / 1024 / 1024
            available_memory = psutil.virtual_memory().available / 1024 / 1024
            
            try:
                # åˆ›å»ºå¤§æ¨¡å‹é…ç½®
                training_config = TrainingConfig()
                training_config.upper_config.total_episodes = 5  # å‡å°‘å›åˆæ•°ä»¥ä¸“æ³¨äºå†…å­˜æµ‹è¯•
                training_config.lower_config.total_episodes = 5
                
                model_config = ModelConfig()
                model_config.upper_layer.hidden_size = hidden_size
                model_config.lower_layer.hidden_size = hidden_size
                model_config.upper_layer.num_layers = 3  # å¢åŠ å±‚æ•°
                model_config.lower_layer.num_layers = 3
                
                # åˆ›å»ºåœºæ™¯
                scenario = self.scenario_generator.generate_scenario(
                    scenario_type=ScenarioType.DAILY_CYCLE,
                    scenario_id=f"memory_limit_test_{hidden_size}"
                )
                
                # åˆ›å»ºç¯å¢ƒ
                env = MultiScaleEnvironment(
                    scenario=scenario,
                    config=training_config.environment_config
                )
                
                # åˆ›å»ºè®­ç»ƒå™¨
                trainer = HierarchicalTrainer(
                    config=training_config,
                    model_config=model_config,
                    trainer_id=f"memory_limit_trainer_{hidden_size}"
                )
                
                # æ‰§è¡Œè®­ç»ƒ
                start_time = time.time()
                training_result = trainer.train(
                    environment=env,
                    num_episodes=5
                )
                execution_time = time.time() - start_time
                
                memory_after = psutil.Process().memory_info().rss / 1024 / 1024
                memory_usage = memory_after - memory_before
                
                # ä¼°ç®—æ¨¡å‹å‚æ•°æ•°é‡
                estimated_params = self._estimate_model_parameters(model_config)
                
                memory_limit_results[hidden_size] = {
                    'memory_usage_mb': memory_usage,
                    'execution_time': execution_time,
                    'estimated_parameters': estimated_params,
                    'memory_per_parameter_bytes': (memory_usage * 1024 * 1024) / estimated_params if estimated_params > 0 else 0,
                    'available_memory_mb': available_memory,
                    'memory_utilization_percent': (memory_usage / available_memory) * 100,
                    'success': True
                }
                
                print(f"  æˆåŠŸ - å†…å­˜ä½¿ç”¨: {memory_usage:.1f}MB, å‚æ•°: {estimated_params:,}")
                
                # å¦‚æœå†…å­˜ä½¿ç”¨è¶…è¿‡80%ï¼Œåœæ­¢æµ‹è¯•
                if memory_usage > available_memory * 0.8:
                    print(f"  è¾¾åˆ°å†…å­˜é™åˆ¶ï¼Œåœæ­¢æµ‹è¯•")
                    break
                    
            except Exception as e:
                print(f"  å¤±è´¥ - {str(e)}")
                memory_limit_results[hidden_size] = {
                    'memory_usage_mb': 0,
                    'success': False,
                    'error': str(e)
                }
                break  # å†…å­˜ä¸è¶³ï¼Œåœæ­¢æµ‹è¯•
        
        # ä¿å­˜ç»“æœ
        self.results['memory_scalability_limits'] = memory_limit_results
        
        print("âœ… å†…å­˜å¯æ‰©å±•æ€§æé™æµ‹è¯•å®Œæˆ")
        self._print_memory_limit_results(memory_limit_results)
    
    def _create_training_task(self, task_id: str, episodes: int) -> Dict[str, Any]:
        """åˆ›å»ºè®­ç»ƒä»»åŠ¡"""
        return {
            'task_id': task_id,
            'episodes': episodes,
            'hidden_size': 64,
            'scenario_type': ScenarioType.DAILY_CYCLE
        }
    
    def _execute_training_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè®­ç»ƒä»»åŠ¡"""
        try:
            # åˆ›å»ºé…ç½®
            training_config = TrainingConfig()
            training_config.upper_config.total_episodes = task['episodes']
            training_config.lower_config.total_episodes = task['episodes']
            
            model_config = ModelConfig()
            model_config.upper_layer.hidden_size = task['hidden_size']
            model_config.lower_layer.hidden_size = task['hidden_size']
            
            # åˆ›å»ºåœºæ™¯
            scenario = self.scenario_generator.generate_scenario(
                scenario_type=task['scenario_type'],
                scenario_id=task['task_id']
            )
            
            # åˆ›å»ºç¯å¢ƒ
            env = MultiScaleEnvironment(
                scenario=scenario,
                config=training_config.environment_config
            )
            
            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = HierarchicalTrainer(
                config=training_config,
                model_config=model_config,
                trainer_id=task['task_id']
            )
            
            # æ‰§è¡Œè®­ç»ƒ
            training_result = trainer.train(
                environment=env,
                num_episodes=task['episodes']
            )
            
            # æå–æ€§èƒ½æŒ‡æ ‡
            if 'training_history' in training_result:
                episode_rewards = [entry.get('episode_reward', 0) for entry in training_result['training_history']]
                final_performance = np.mean(episode_rewards[-5:]) if len(episode_rewards) >= 5 else 0
            else:
                final_performance = 0
            
            return {
                'task_id': task['task_id'],
                'episodes_completed': task['episodes'],
                'final_performance': final_performance,
                'success': True
            }
            
        except Exception as e:
            return {
                'task_id': task['task_id'],
                'episodes_completed': 0,
                'final_performance': 0,
                'success': False,
                'error': str(e)
            }
    
    def _estimate_model_parameters(self, model_config: ModelConfig) -> int:
        """ä¼°ç®—æ¨¡å‹å‚æ•°æ•°é‡"""
        upper_params = (
            model_config.upper_layer.state_dim * model_config.upper_layer.hidden_size +
            model_config.upper_layer.hidden_size * model_config.upper_layer.hidden_size * (model_config.upper_layer.num_layers - 1) +
            model_config.upper_layer.hidden_size * model_config.upper_layer.action_dim
        )
        
        lower_params = (
            model_config.lower_layer.state_dim * model_config.lower_layer.hidden_size +
            model_config.lower_layer.hidden_size * model_config.lower_layer.hidden_size * (model_config.lower_layer.num_layers - 1) +
            model_config.lower_layer.hidden_size * model_config.lower_layer.action_dim
        )
        
        return upper_params + lower_params
    
    def _analyze_battery_scalability(self, results: Dict[int, Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æç”µæ± å¯æ‰©å±•æ€§"""
        successful_results = {k: v for k, v in results.items() if v['success']}
        
        if len(successful_results) < 2:
            return {'scalability_factor': 0, 'linear_scalability': False}
        
        battery_counts = list(successful_results.keys())
        execution_times = [successful_results[k]['execution_time'] for k in battery_counts]
        memory_usages = [successful_results[k]['memory_usage_mb'] for k in battery_counts]
        
        # è®¡ç®—çº¿æ€§å›å½’æ–œç‡
        time_slope = np.polyfit(battery_counts, execution_times, 1)[0]
        memory_slope = np.polyfit(battery_counts, memory_usages, 1)[0]
        
        # è¯„ä¼°çº¿æ€§å¯æ‰©å±•æ€§
        time_correlation = np.corrcoef(battery_counts, execution_times)[0, 1]
        memory_correlation = np.corrcoef(battery_counts, memory_usages)[0, 1]
        
        return {
            'time_slope': time_slope,
            'memory_slope': memory_slope,
            'time_correlation': time_correlation,
            'memory_correlation': memory_correlation,
            'linear_scalability': time_correlation > 0.8 and memory_correlation > 0.8,
            'max_tested_batteries': max(battery_counts),
            'scalability_factor': time_slope
        }
    
    def _print_battery_scalability_results(self, results: Dict[int, Dict[str, Any]], analysis: Dict[str, Any]):
        """æ‰“å°ç”µæ± å¯æ‰©å±•æ€§ç»“æœ"""
        print("\nğŸ”‹ ç”µæ± æ•°é‡å¯æ‰©å±•æ€§æµ‹è¯•ç»“æœ:")
        print("=" * 80)
        for num_batteries, result in results.items():
            if result['success']:
                print(f"ç”µæ± æ•° {num_batteries:>3}: æ—¶é—´={result['execution_time']:>6.2f}s, "
                      f"å†…å­˜={result['memory_usage_mb']:>6.1f}MB, "
                      f"ååé‡={result['throughput_steps_per_sec']:>6.1f}steps/s")
            else:
                print(f"ç”µæ± æ•° {num_batteries:>3}: å¤±è´¥ - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        print(f"\nåˆ†æç»“æœ:")
        print(f"  çº¿æ€§å¯æ‰©å±•æ€§: {'æ˜¯' if analysis['linear_scalability'] else 'å¦'}")
        print(f"  æ—¶é—´ç›¸å…³æ€§: {analysis['time_correlation']:.3f}")
        print(f"  å†…å­˜ç›¸å…³æ€§: {analysis['memory_correlation']:.3f}")
    
    def _print_episode_scalability_results(self, results: Dict[int, Dict[str, Any]]):
        """æ‰“å°å›åˆæ•°å¯æ‰©å±•æ€§ç»“æœ"""
        print("\nğŸ“ˆ è®­ç»ƒå›åˆæ•°å¯æ‰©å±•æ€§æµ‹è¯•ç»“æœ:")
        print("=" * 80)
        for num_episodes, result in results.items():
            if result['success']:
                print(f"å›åˆæ•° {num_episodes:>4}: æ—¶é—´={result['execution_time']:>6.2f}s, "
                      f"å†…å­˜={result['memory_usage_mb']:>6.1f}MB, "
                      f"CPU={result['avg_cpu_percent']:>5.1f}%")
            else:
                print(f"å›åˆæ•° {num_episodes:>4}: å¤±è´¥ - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    def _print_parallel_scalability_results(self, results: Dict[int, Dict[str, Any]]):
        """æ‰“å°å¹¶è¡Œå¯æ‰©å±•æ€§ç»“æœ"""
        print("\nâš¡ å¹¶è¡Œå¤„ç†å¯æ‰©å±•æ€§æµ‹è¯•ç»“æœ:")
        print("=" * 80)
        for num_workers, result in results.items():
            if result['success']:
                print(f"Workeræ•° {num_workers:>2}: æ—¶é—´={result['execution_time']:>6.2f}s, "
                      f"åŠ é€Ÿæ¯”={result['speedup']:>5.2f}x, "
                      f"æ•ˆç‡={result['efficiency']:>5.2f}")
            else:
                print(f"Workeræ•° {num_workers:>2}: å¤±è´¥ - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    def _print_memory_limit_results(self, results: Dict[int, Dict[str, Any]]):
        """æ‰“å°å†…å­˜æé™ç»“æœ"""
        print("\nğŸ§  å†…å­˜å¯æ‰©å±•æ€§æé™æµ‹è¯•ç»“æœ:")
        print("=" * 80)
        for hidden_size, result in results.items():
            if result['success']:
                print(f"éšè—å±‚ {hidden_size:>4}: å†…å­˜={result['memory_usage_mb']:>6.1f}MB, "
                      f"å‚æ•°={result['estimated_parameters']:>8,}, "
                      f"åˆ©ç”¨ç‡={result['memory_utilization_percent']:>5.1f}%")
            else:
                print(f"éšè—å±‚ {hidden_size:>4}: å¤±è´¥ - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    def save_scalability_results(self, filepath: str = "scalability_test_results.json"):
        """ä¿å­˜å¯æ‰©å±•æ€§æµ‹è¯•ç»“æœ"""
        with open(filepath, 'w') as f:
            json.dump(self.results, f, indent=2, default=str)
        print(f"ğŸ“ å¯æ‰©å±•æ€§æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filepath}")


class ResourceMonitor:
    """èµ„æºç›‘æ§å™¨"""
    
    def __init__(self):
        self.monitoring = False
        self.cpu_data = []
        self.memory_data = []
        self.monitor_thread = None
    
    def start(self):
        """å¼€å§‹ç›‘æ§"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.start()
    
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
            
            self.cpu_data.append(cpu_percent)
            self.memory_data.append(memory_mb)
            
            time.sleep(0.5)
    
    def get_cpu_stats(self) -> Dict[str, float]:
        """è·å–CPUç»Ÿè®¡"""
        if not self.cpu_data:
            return {'avg_cpu_percent': 0, 'max_cpu_percent': 0}
        
        return {
            'avg_cpu_percent': np.mean(self.cpu_data),
            'max_cpu_percent': np.max(self.cpu_data)
        }
    
    def get_memory_stats(self) -> Dict[str, float]:
        """è·å–å†…å­˜ç»Ÿè®¡"""
        if not self.memory_data:
            return {'avg_memory_mb': 0, 'max_memory_mb': 0}
        
        return {
            'avg_memory_mb': np.mean(self.memory_data),
            'max_memory_mb': np.max(self.memory_data)
        }


if __name__ == '__main__':
    unittest.main()
