"""
DRLæ¨¡å‹é…ç½® - BMSé›†ç¾¤ç‰ˆæœ¬
ç»´åº¦ä¸ç¯å¢ƒçŠ¶æ€åŒ¹é…
"""

from dataclasses import dataclass
from enum import Enum

class ModelType(Enum):
    TRANSFORMER = "transformer"
    LSTM = "lstm" 
    GRU = "gru"
    MLP = "mlp"

class LayerType(Enum):
    UPPER = "upper"
    LOWER = "lower"

@dataclass
class ModelConfig:
    """DRLæ¨¡å‹é…ç½® - æ”¯æŒBMSé›†ç¾¤"""
    
    # === ä¸Šå±‚æ¨¡å‹é…ç½® ===
    upper_model_type: ModelType = ModelType.TRANSFORMER
    upper_state_dim: int = 24      # ä¸storage_environmentçš„24ç»´çŠ¶æ€åŒ¹é…
    upper_action_dim: int = 5      # [åŠŸç‡æŒ‡ä»¤, SOCæƒé‡, æ¸©åº¦æƒé‡, å¯¿å‘½æƒé‡, æ•ˆç‡æƒé‡]
    upper_hidden_dim: int = 256
    
    # === ä¸‹å±‚æ¨¡å‹é…ç½® ===  
    lower_model_type: ModelType = ModelType.MLP
    lower_state_dim: int = 32      # ä¸‹å±‚æ¥æ”¶æ›´è¯¦ç»†çš„çŠ¶æ€ä¿¡æ¯
    lower_action_dim: int = 3      # [å®é™…åŠŸç‡æ‰§è¡Œ, å“åº”é€Ÿåº¦, è¯¯å·®è¡¥å¿]
    lower_hidden_dim: int = 128
    
    # === BMSé›†ç¾¤ç‰¹å®šé…ç½® ===
    bms_cluster_features: bool = True
    num_bms: int = 10              # BMSæ•°é‡
    inter_bms_attention: bool = True   # BMSé—´æ³¨æ„åŠ›æœºåˆ¶
    intra_bms_attention: bool = True   # BMSå†…æ³¨æ„åŠ›æœºåˆ¶
    
    # === çŠ¶æ€å¤„ç†é…ç½® ===
    state_normalization: str = "external"  # "internal" | "external" | "none"
    state_history_length: int = 10        # çŠ¶æ€å†å²é•¿åº¦
    enable_state_filtering: bool = True   # å¯ç”¨çŠ¶æ€æ»¤æ³¢
    
    # === ç‰¹å¾æå–é…ç½® ===
    enable_attention: bool = True
    attention_heads: int = 8
    dropout_rate: float = 0.1
    batch_norm: bool = True
    layer_norm: bool = True
    
    # === å¤šå±‚çº§æ¶æ„é…ç½® ===
    hierarchical_levels: int = 2          # å±‚çº§æ•°é‡
    cross_level_communication: bool = True # è·¨å±‚çº§é€šä¿¡
    level_coordination_dim: int = 64      # å±‚çº§åè°ƒç»´åº¦
    
    # === çº¦æŸå¤„ç†é…ç½® ===
    constraint_handling_method: str = "penalty"  # "penalty" | "barrier" | "projection"
    constraint_penalty_weight: float = 10.0
    safety_margin: float = 0.1
    adaptive_constraints: bool = True     # è‡ªé€‚åº”çº¦æŸ
    
    # === è®­ç»ƒé…ç½® ===
    learning_rate_upper: float = 3e-4
    learning_rate_lower: float = 1e-3
    weight_decay: float = 1e-5
    gradient_clip_norm: float = 1.0
    
    # === ç»éªŒå›æ”¾é…ç½® ===
    buffer_size: int = 100000
    batch_size: int = 64
    prioritized_replay: bool = True
    replay_alpha: float = 0.6
    replay_beta: float = 0.4
    
    # === æ¢ç´¢é…ç½® ===
    exploration_method: str = "noise"  # "noise" | "epsilon" | "entropy"
    initial_noise_scale: float = 0.2
    noise_decay_rate: float = 0.995
    min_noise_scale: float = 0.01
    
    # === ç½‘ç»œæ¶æ„è¯¦ç»†é…ç½® ===
    
    # ç¼–ç å™¨é…ç½®
    encoder_layers: int = 3
    encoder_hidden_dims: list = None  # [512, 256, 128]
    
    # è§£ç å™¨é…ç½®  
    decoder_layers: int = 2
    decoder_hidden_dims: list = None  # [128, 64]
    
    # æ³¨æ„åŠ›æœºåˆ¶é…ç½®
    attention_temperature: float = 1.0
    attention_dropout: float = 0.1
    
    # æ¿€æ´»å‡½æ•°é…ç½®
    activation_function: str = "gelu"  # "relu" | "gelu" | "swish" | "leaky_relu"
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†"""
        
        # è®¾ç½®é»˜è®¤çš„éšè—å±‚ç»´åº¦
        if self.encoder_hidden_dims is None:
            self.encoder_hidden_dims = [self.upper_hidden_dim * 2, self.upper_hidden_dim, self.upper_hidden_dim // 2]
        
        if self.decoder_hidden_dims is None:
            self.decoder_hidden_dims = [self.upper_hidden_dim // 2, self.upper_hidden_dim // 4]
        
        # éªŒè¯é…ç½®çš„ä¸€è‡´æ€§
        self._validate_config()
    
    def _validate_config(self):
        """éªŒè¯é…ç½®ä¸€è‡´æ€§"""
        
        # æ£€æŸ¥çŠ¶æ€ç»´åº¦åŒ¹é…
        if self.upper_state_dim != 24:
            print(f"âš ï¸ ä¸Šå±‚çŠ¶æ€ç»´åº¦ {self.upper_state_dim} ä¸ç¯å¢ƒçŠ¶æ€ç»´åº¦ 24 ä¸åŒ¹é…")
        
        # æ£€æŸ¥åŠ¨ä½œç»´åº¦
        if self.upper_action_dim != 5:
            print(f"âš ï¸ ä¸Šå±‚åŠ¨ä½œç»´åº¦ {self.upper_action_dim} ä¸ç¯å¢ƒåŠ¨ä½œç»´åº¦ 5 ä¸åŒ¹é…")
        
        # æ£€æŸ¥BMSæ•°é‡
        if self.num_bms <= 0:
            raise ValueError("BMSæ•°é‡å¿…é¡»å¤§äº0")
        
        # æ£€æŸ¥éšè—å±‚ç»´åº¦
        if len(self.encoder_hidden_dims) != self.encoder_layers:
            print(f"âš ï¸ ç¼–ç å™¨å±‚æ•°ä¸éšè—ç»´åº¦åˆ—è¡¨é•¿åº¦ä¸åŒ¹é…")
        
        # æ£€æŸ¥å­¦ä¹ ç‡
        if self.learning_rate_upper <= 0 or self.learning_rate_lower <= 0:
            raise ValueError("å­¦ä¹ ç‡å¿…é¡»å¤§äº0")
        
        print(f"âœ… æ¨¡å‹é…ç½®éªŒè¯é€šè¿‡: ä¸Šå±‚{self.upper_state_dim}â†’{self.upper_action_dim}, ä¸‹å±‚{self.lower_state_dim}â†’{self.lower_action_dim}")
    
    def get_upper_layer_config(self) -> dict:
        """è·å–ä¸Šå±‚é…ç½®å­—å…¸"""
        return {
            'model_type': self.upper_model_type,
            'state_dim': self.upper_state_dim,
            'action_dim': self.upper_action_dim,
            'hidden_dim': self.upper_hidden_dim,
            'attention_enabled': self.enable_attention,
            'attention_heads': self.attention_heads,
            'dropout_rate': self.dropout_rate,
            'batch_norm': self.batch_norm,
            'layer_norm': self.layer_norm,
            'learning_rate': self.learning_rate_upper,
            'bms_cluster_features': self.bms_cluster_features,
            'num_bms': self.num_bms,
            'inter_bms_attention': self.inter_bms_attention
        }
    
    def get_lower_layer_config(self) -> dict:
        """è·å–ä¸‹å±‚é…ç½®å­—å…¸"""
        return {
            'model_type': self.lower_model_type,
            'state_dim': self.lower_state_dim,
            'action_dim': self.lower_action_dim,
            'hidden_dim': self.lower_hidden_dim,
            'dropout_rate': self.dropout_rate,
            'batch_norm': self.batch_norm,
            'learning_rate': self.learning_rate_lower,
            'intra_bms_attention': self.intra_bms_attention
        }
    
    def get_constraint_config(self) -> dict:
        """è·å–çº¦æŸå¤„ç†é…ç½®"""
        return {
            'method': self.constraint_handling_method,
            'penalty_weight': self.constraint_penalty_weight,
            'safety_margin': self.safety_margin,
            'adaptive': self.adaptive_constraints
        }
    
    def get_training_config(self) -> dict:
        """è·å–è®­ç»ƒé…ç½®"""
        return {
            'buffer_size': self.buffer_size,
            'batch_size': self.batch_size,
            'prioritized_replay': self.prioritized_replay,
            'replay_alpha': self.replay_alpha,
            'replay_beta': self.replay_beta,
            'weight_decay': self.weight_decay,
            'gradient_clip_norm': self.gradient_clip_norm,
            'exploration_method': self.exploration_method,
            'initial_noise_scale': self.initial_noise_scale,
            'noise_decay_rate': self.noise_decay_rate,
            'min_noise_scale': self.min_noise_scale
        }
    
    def update_for_environment(self, env_info: dict):
        """æ ¹æ®ç¯å¢ƒä¿¡æ¯æ›´æ–°é…ç½®"""
        
        if 'state_dim' in env_info:
            self.upper_state_dim = env_info['state_dim']
        
        if 'action_dim' in env_info:
            self.upper_action_dim = env_info['action_dim']
        
        if 'num_bms' in env_info:
            self.num_bms = env_info['num_bms']
        
        # é‡æ–°éªŒè¯é…ç½®
        self._validate_config()
        
        print(f"ğŸ”„ æ¨¡å‹é…ç½®å·²æ ¹æ®ç¯å¢ƒä¿¡æ¯æ›´æ–°")
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (f"ModelConfig: ä¸Šå±‚({self.upper_model_type.value}): "
                f"{self.upper_state_dim}â†’{self.upper_action_dim}, "
                f"ä¸‹å±‚({self.lower_model_type.value}): "
                f"{self.lower_state_dim}â†’{self.lower_action_dim}, "
                f"BMSé›†ç¾¤: {self.num_bms}ä¸ª")
