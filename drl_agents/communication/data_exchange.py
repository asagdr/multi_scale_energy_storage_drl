import numpy as np
import torch
import json
import time
import threading
from typing import Dict, List, Optional, Tuple, Any, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
import queue
import pickle
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from .message_protocol import MessageProtocol, Priority
from .information_flow import InformationFlow, InformationType

class ExchangeMode(Enum):
    """æ•°æ®äº¤æ¢æ¨¡å¼æšä¸¾"""
    SYNCHRONOUS = "synchronous"         # åŒæ­¥æ¨¡å¼
    ASYNCHRONOUS = "asynchronous"       # å¼‚æ­¥æ¨¡å¼
    BUFFERED = "buffered"              # ç¼“å†²æ¨¡å¼
    STREAMING = "streaming"            # æµå¼æ¨¡å¼

class DataFormat(Enum):
    """æ•°æ®æ ¼å¼æšä¸¾"""
    JSON = "json"                      # JSONæ ¼å¼
    BINARY = "binary"                  # äºŒè¿›åˆ¶æ ¼å¼
    PICKLE = "pickle"                  # Pickleåºåˆ—åŒ–
    NUMPY = "numpy"                    # NumPyæ ¼å¼
    TORCH = "torch"                    # PyTorchæ ¼å¼

@dataclass
class DataSchema:
    """æ•°æ®æ¨¡å¼å®šä¹‰"""
    schema_id: str
    data_type: str
    required_fields: List[str]
    optional_fields: List[str] = field(default_factory=list)
    validation_rules: Dict[str, callable] = field(default_factory=dict)
    format_specification: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ExchangeTransaction:
    """æ•°æ®äº¤æ¢äº‹åŠ¡"""
    transaction_id: str
    exchange_type: str
    source_node: str
    target_node: str
    data_schema: DataSchema
    start_time: float
    end_time: Optional[float] = None
    status: str = "pending"  # pending, completed, failed, timeout
    error_message: Optional[str] = None
    retry_count: int = 0
    max_retries: int = 3

class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""
    
    def __init__(self):
        self.registered_schemas: Dict[str, DataSchema] = {}
        self.validation_errors = []
    
    def register_schema(self, schema: DataSchema) -> bool:
        """æ³¨å†Œæ•°æ®æ¨¡å¼"""
        try:
            self.registered_schemas[schema.schema_id] = schema
            print(f"âœ… å·²æ³¨å†Œæ•°æ®æ¨¡å¼: {schema.schema_id}")
            return True
        except Exception as e:
            print(f"âŒ æ³¨å†Œæ•°æ®æ¨¡å¼å¤±è´¥: {str(e)}")
            return False
    
    def validate_data(self, data: Dict[str, Any], schema_id: str) -> Tuple[bool, List[str]]:
        """éªŒè¯æ•°æ®"""
        if schema_id not in self.registered_schemas:
            return False, [f"æœªæ‰¾åˆ°æ•°æ®æ¨¡å¼: {schema_id}"]
        
        schema = self.registered_schemas[schema_id]
        errors = []
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        for field in schema.required_fields:
            if field not in data:
                errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        # åº”ç”¨éªŒè¯è§„åˆ™
        for field, rule in schema.validation_rules.items():
            if field in data:
                try:
                    if not rule(data[field]):
                        errors.append(f"å­—æ®µéªŒè¯å¤±è´¥: {field}")
                except Exception as e:
                    errors.append(f"éªŒè¯è§„åˆ™æ‰§è¡Œé”™è¯¯: {field} - {str(e)}")
        
        is_valid = len(errors) == 0
        if not is_valid:
            self.validation_errors.extend(errors)
        
        return is_valid, errors

class DataSerializer:
    """æ•°æ®åºåˆ—åŒ–å™¨"""
    
    def __init__(self):
        self.serializers = {
            DataFormat.JSON: self._json_serialize,
            DataFormat.BINARY: self._binary_serialize,
            DataFormat.PICKLE: self._pickle_serialize,
            DataFormat.NUMPY: self._numpy_serialize,
            DataFormat.TORCH: self._torch_serialize
        }
        
        self.deserializers = {
            DataFormat.JSON: self._json_deserialize,
            DataFormat.BINARY: self._binary_deserialize,
            DataFormat.PICKLE: self._pickle_deserialize,
            DataFormat.NUMPY: self._numpy_deserialize,
            DataFormat.TORCH: self._torch_deserialize
        }
    
    def serialize(self, data: Any, format_type: DataFormat) -> bytes:
        """åºåˆ—åŒ–æ•°æ®"""
        try:
            serializer = self.serializers.get(format_type)
            if serializer:
                return serializer(data)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„åºåˆ—åŒ–æ ¼å¼: {format_type}")
        except Exception as e:
            print(f"âŒ æ•°æ®åºåˆ—åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def deserialize(self, data: bytes, format_type: DataFormat) -> Any:
        """ååºåˆ—åŒ–æ•°æ®"""
        try:
            deserializer = self.deserializers.get(format_type)
            if deserializer:
                return deserializer(data)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ååºåˆ—åŒ–æ ¼å¼: {format_type}")
        except Exception as e:
            print(f"âŒ æ•°æ®ååºåˆ—åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def _json_serialize(self, data: Any) -> bytes:
        """JSONåºåˆ—åŒ–"""
        # å¤„ç†NumPyæ•°ç»„å’ŒPyTorchå¼ é‡
        if isinstance(data, np.ndarray):
            data = {'type': 'numpy', 'data': data.tolist(), 'shape': data.shape, 'dtype': str(data.dtype)}
        elif isinstance(data, torch.Tensor):
            data = {'type': 'torch', 'data': data.detach().cpu().numpy().tolist(), 'shape': list(data.shape)}
        
        return json.dumps(data, default=str).encode('utf-8')
    
    def _json_deserialize(self, data: bytes) -> Any:
        """JSONååºåˆ—åŒ–"""
        decoded_data = json.loads(data.decode('utf-8'))
        
        # æ¢å¤NumPyæ•°ç»„å’ŒPyTorchå¼ é‡
        if isinstance(decoded_data, dict):
            if decoded_data.get('type') == 'numpy':
                return np.array(decoded_data['data']).reshape(decoded_data['shape']).astype(decoded_data['dtype'])
            elif decoded_data.get('type') == 'torch':
                return torch.tensor(decoded_data['data']).reshape(decoded_data['shape'])
        
        return decoded_data
    
    def _binary_serialize(self, data: Any) -> bytes:
        """äºŒè¿›åˆ¶åºåˆ—åŒ–"""
        return pickle.dumps(data)
    
    def _binary_deserialize(self, data: bytes) -> Any:
        """äºŒè¿›åˆ¶ååºåˆ—åŒ–"""
        return pickle.loads(data)
    
    def _pickle_serialize(self, data: Any) -> bytes:
        """Pickleåºåˆ—åŒ–"""
        return pickle.dumps(data)
    
    def _pickle_deserialize(self, data: bytes) -> Any:
        """Pickleååºåˆ—åŒ–"""
        return pickle.loads(data)
    
    def _numpy_serialize(self, data: np.ndarray) -> bytes:
        """NumPyåºåˆ—åŒ–"""
        import io
        buffer = io.BytesIO()
        np.save(buffer, data)
        return buffer.getvalue()
    
    def _numpy_deserialize(self, data: bytes) -> np.ndarray:
        """NumPyååºåˆ—åŒ–"""
        import io
        buffer = io.BytesIO(data)
        return np.load(buffer)
    
    def _torch_serialize(self, data: torch.Tensor) -> bytes:
        """PyTorchåºåˆ—åŒ–"""
        import io
        buffer = io.BytesIO()
        torch.save(data, buffer)
        return buffer.getvalue()
    
    def _torch_deserialize(self, data: bytes) -> torch.Tensor:
        """PyTorchååºåˆ—åŒ–"""
        import io
        buffer = io.BytesIO(data)
        return torch.load(buffer, map_location='cpu')

class DataExchange:
    """
    æ•°æ®äº¤æ¢å™¨
    æä¾›ä¸Šä¸‹å±‚DRLä¹‹é—´çš„é«˜çº§æ•°æ®äº¤æ¢æœåŠ¡
    """
    
    def __init__(self, 
                 exchange_id: str,
                 message_protocol: MessageProtocol,
                 information_flow: InformationFlow):
        """
        åˆå§‹åŒ–æ•°æ®äº¤æ¢å™¨
        
        Args:
            exchange_id: äº¤æ¢å™¨ID
            message_protocol: æ¶ˆæ¯åè®®
            information_flow: ä¿¡æ¯æµç®¡ç†å™¨
        """
        self.exchange_id = exchange_id
        self.message_protocol = message_protocol
        self.information_flow = information_flow
        
        # === æ ¸å¿ƒç»„ä»¶ ===
        self.data_validator = DataValidator()
        self.data_serializer = DataSerializer()
        
        # === äº¤æ¢é…ç½® ===
        self.exchange_config = {
            'default_mode': ExchangeMode.ASYNCHRONOUS,
            'default_format': DataFormat.JSON,
            'timeout': 30.0,
            'max_retries': 3,
            'buffer_size': 1000,
            'compression_enabled': True,
            'encryption_enabled': False
        }
        
        # === äº‹åŠ¡ç®¡ç† ===
        self.active_transactions: Dict[str, ExchangeTransaction] = {}
        self.completed_transactions: List[ExchangeTransaction] = []
        self.transaction_lock = threading.Lock()
        
        # === æ•°æ®ç¼“å†²åŒº ===
        self.data_buffers: Dict[str, queue.Queue] = {
            'constraint_matrix': queue.Queue(maxsize=10),
            'weight_vector': queue.Queue(maxsize=10),
            'performance_feedback': queue.Queue(maxsize=100),
            'system_state': queue.Queue(maxsize=100),
            'alarm_data': queue.Queue(maxsize=50)
        }
        
        # === å›è°ƒå‡½æ•° ===
        self.data_callbacks: Dict[str, List[Callable]] = {}
        
        # === ç»Ÿè®¡ä¿¡æ¯ ===
        self.exchange_statistics = {
            'total_exchanges': 0,
            'successful_exchanges': 0,
            'failed_exchanges': 0,
            'timeout_exchanges': 0,
            'total_bytes_exchanged': 0,
            'average_exchange_time': 0.0
        }
        
        # === æ³¨å†Œé»˜è®¤æ•°æ®æ¨¡å¼ ===
        self._register_default_schemas()
        
        print(f"âœ… æ•°æ®äº¤æ¢å™¨åˆå§‹åŒ–å®Œæˆ: {exchange_id}")
    
    def _register_default_schemas(self):
        """æ³¨å†Œé»˜è®¤æ•°æ®æ¨¡å¼"""
        # çº¦æŸçŸ©é˜µæ¨¡å¼
        constraint_schema = DataSchema(
            schema_id="constraint_matrix",
            data_type="tensor",
            required_fields=["constraint_matrix", "matrix_shape", "constraint_type"],
            optional_fields=["validity_period", "priority_level"],
            validation_rules={
                "constraint_matrix": lambda x: isinstance(x, (list, np.ndarray, torch.Tensor)),
                "matrix_shape": lambda x: isinstance(x, (list, tuple)) and len(x) >= 2
            }
        )
        self.data_validator.register_schema(constraint_schema)
        
        # æƒé‡å‘é‡æ¨¡å¼
        weight_schema = DataSchema(
            schema_id="weight_vector",
            data_type="vector",
            required_fields=["weight_vector", "vector_length", "weight_type"],
            optional_fields=["normalization"],
            validation_rules={
                "weight_vector": lambda x: isinstance(x, (list, np.ndarray, torch.Tensor)),
                "vector_length": lambda x: isinstance(x, int) and x > 0,
                "weight_type": lambda x: isinstance(x, str)
            }
        )
        self.data_validator.register_schema(weight_schema)
        
        # æ€§èƒ½åé¦ˆæ¨¡å¼
        performance_schema = DataSchema(
            schema_id="performance_feedback",
            data_type="metrics",
            required_fields=["performance_metrics", "measurement_time"],
            optional_fields=["metrics_type", "confidence_level"],
            validation_rules={
                "performance_metrics": lambda x: isinstance(x, dict),
                "measurement_time": lambda x: isinstance(x, (int, float))
            }
        )
        self.data_validator.register_schema(performance_schema)
        
        # ç³»ç»ŸçŠ¶æ€æ¨¡å¼
        state_schema = DataSchema(
            schema_id="system_state",
            data_type="state",
            required_fields=["system_state", "state_timestamp"],
            optional_fields=["state_type", "sensor_data"],
            validation_rules={
                "system_state": lambda x: isinstance(x, dict),
                "state_timestamp": lambda x: isinstance(x, (int, float))
            }
        )
        self.data_validator.register_schema(state_schema)
        
        # å‘Šè­¦æ•°æ®æ¨¡å¼
        alarm_schema = DataSchema(
            schema_id="alarm_data",
            data_type="alarm",
            required_fields=["alarm_info", "alarm_timestamp", "severity"],
            optional_fields=["alarm_source", "recommended_actions"],
            validation_rules={
                "alarm_info": lambda x: isinstance(x, dict),
                "alarm_timestamp": lambda x: isinstance(x, (int, float)),
                "severity": lambda x: isinstance(x, str) and x in ["low", "medium", "high", "critical"]
            }
        )
        self.data_validator.register_schema(alarm_schema)
    
    def exchange_constraint_matrix(self, 
                                 constraint_matrix: torch.Tensor,
                                 target_node: str,
                                 mode: ExchangeMode = ExchangeMode.ASYNCHRONOUS,
                                 priority: Priority = Priority.HIGH) -> str:
        """
        äº¤æ¢çº¦æŸçŸ©é˜µ
        
        Args:
            constraint_matrix: çº¦æŸçŸ©é˜µ
            target_node: ç›®æ ‡èŠ‚ç‚¹
            mode: äº¤æ¢æ¨¡å¼
            priority: ä¼˜å…ˆçº§
            
        Returns:
            äº‹åŠ¡ID
        """
        try:
            # åˆ›å»ºäº‹åŠ¡
            transaction_id = f"constraint_{int(time.time()*1000)}"
            transaction = ExchangeTransaction(
                transaction_id=transaction_id,
                exchange_type="constraint_matrix",
                source_node=self.exchange_id,
                target_node=target_node,
                data_schema=self.data_validator.registered_schemas["constraint_matrix"],
                start_time=time.time()
            )
            
            # å‡†å¤‡æ•°æ®
            data = {
                "constraint_matrix": constraint_matrix.detach().cpu().numpy().tolist(),
                "matrix_shape": list(constraint_matrix.shape),
                "constraint_type": "dynamic_operational_constraints",
                "validity_period": 300.0,
                "priority_level": priority.value
            }
            
            # éªŒè¯æ•°æ®
            is_valid, errors = self.data_validator.validate_data(data, "constraint_matrix")
            if not is_valid:
                transaction.status = "failed"
                transaction.error_message = f"æ•°æ®éªŒè¯å¤±è´¥: {errors}"
                return transaction_id
            
            # æ‰§è¡Œäº¤æ¢
            success = self._execute_exchange(transaction, data, mode)
            
            if success:
                transaction.status = "completed"
                self.exchange_statistics['successful_exchanges'] += 1
            else:
                transaction.status = "failed"
                self.exchange_statistics['failed_exchanges'] += 1
            
            transaction.end_time = time.time()
            
            # æ›´æ–°ç»Ÿè®¡
            self.exchange_statistics['total_exchanges'] += 1
            exchange_time = transaction.end_time - transaction.start_time
            self.exchange_statistics['average_exchange_time'] = (
                self.exchange_statistics['average_exchange_time'] * 0.9 + exchange_time * 0.1
            )
            
            # ç®¡ç†äº‹åŠ¡
            with self.transaction_lock:
                if transaction_id in self.active_transactions:
                    del self.active_transactions[transaction_id]
                self.completed_transactions.append(transaction)
                
                # ç»´æŠ¤å†å²é•¿åº¦
                if len(self.completed_transactions) > 1000:
                    self.completed_transactions.pop(0)
            
            return transaction_id
            
        except Exception as e:
            print(f"âŒ çº¦æŸçŸ©é˜µäº¤æ¢å¤±è´¥: {str(e)}")
            self.exchange_statistics['failed_exchanges'] += 1
            return ""
    
    def exchange_weight_vector(self, 
                             weight_vector: torch.Tensor,
                             target_node: str,
                             mode: ExchangeMode = ExchangeMode.ASYNCHRONOUS,
                             priority: Priority = Priority.HIGH) -> str:
        """
        äº¤æ¢æƒé‡å‘é‡
        
        Args:
            weight_vector: æƒé‡å‘é‡
            target_node: ç›®æ ‡èŠ‚ç‚¹
            mode: äº¤æ¢æ¨¡å¼
            priority: ä¼˜å…ˆçº§
            
        Returns:
            äº‹åŠ¡ID
        """
        try:
            transaction_id = f"weight_{int(time.time()*1000)}"
            transaction = ExchangeTransaction(
                transaction_id=transaction_id,
                exchange_type="weight_vector",
                source_node=self.exchange_id,
                target_node=target_node,
                data_schema=self.data_validator.registered_schemas["weight_vector"],
                start_time=time.time()
            )
            
            data = {
                "weight_vector": weight_vector.detach().cpu().numpy().tolist(),
                "vector_length": len(weight_vector),
                "weight_type": "multi_objective_weights",
                "normalization": "sum_to_one"
            }
            
            is_valid, errors = self.data_validator.validate_data(data, "weight_vector")
            if not is_valid:
                transaction.status = "failed"
                transaction.error_message = f"æ•°æ®éªŒè¯å¤±è´¥: {errors}"
                return transaction_id
            
            success = self._execute_exchange(transaction, data, mode)
            
            transaction.status = "completed" if success else "failed"
            transaction.end_time = time.time()
            
            self._update_transaction_statistics(transaction, success)
            
            return transaction_id
            
        except Exception as e:
            print(f"âŒ æƒé‡å‘é‡äº¤æ¢å¤±è´¥: {str(e)}")
            self.exchange_statistics['failed_exchanges'] += 1
            return ""
    
    def exchange_performance_feedback(self, 
                                    performance_data: Dict[str, Any],
                                    target_node: str,
                                    mode: ExchangeMode = ExchangeMode.BUFFERED) -> str:
        """
        äº¤æ¢æ€§èƒ½åé¦ˆ
        
        Args:
            performance_data: æ€§èƒ½æ•°æ®
            target_node: ç›®æ ‡èŠ‚ç‚¹
            mode: äº¤æ¢æ¨¡å¼
            
        Returns:
            äº‹åŠ¡ID
        """
        try:
            transaction_id = f"perf_{int(time.time()*1000)}"
            transaction = ExchangeTransaction(
                transaction_id=transaction_id,
                exchange_type="performance_feedback",
                source_node=self.exchange_id,
                target_node=target_node,
                data_schema=self.data_validator.registered_schemas["performance_feedback"],
                start_time=time.time()
            )
            
            data = {
                "performance_metrics": performance_data,
                "measurement_time": time.time(),
                "metrics_type": "real_time_performance"
            }
            
            is_valid, errors = self.data_validator.validate_data(data, "performance_feedback")
            if not is_valid:
                transaction.status = "failed"
                transaction.error_message = f"æ•°æ®éªŒè¯å¤±è´¥: {errors}"
                return transaction_id
            
            success = self._execute_exchange(transaction, data, mode)
            
            transaction.status = "completed" if success else "failed"
            transaction.end_time = time.time()
            
            self._update_transaction_statistics(transaction, success)
            
            return transaction_id
            
        except Exception as e:
            print(f"âŒ æ€§èƒ½åé¦ˆäº¤æ¢å¤±è´¥: {str(e)}")
            self.exchange_statistics['failed_exchanges'] += 1
            return ""
    
    def _execute_exchange(self, 
                         transaction: ExchangeTransaction,
                         data: Dict[str, Any],
                         mode: ExchangeMode) -> bool:
        """æ‰§è¡Œæ•°æ®äº¤æ¢"""
        try:
            with self.transaction_lock:
                self.active_transactions[transaction.transaction_id] = transaction
            
            if mode == ExchangeMode.SYNCHRONOUS:
                return self._synchronous_exchange(transaction, data)
            elif mode == ExchangeMode.ASYNCHRONOUS:
                return self._asynchronous_exchange(transaction, data)
            elif mode == ExchangeMode.BUFFERED:
                return self._buffered_exchange(transaction, data)
            elif mode == ExchangeMode.STREAMING:
                return self._streaming_exchange(transaction, data)
            else:
                print(f"âš ï¸ ä¸æ”¯æŒçš„äº¤æ¢æ¨¡å¼: {mode}")
                return False
                
        except Exception as e:
            print(f"âŒ æ‰§è¡Œæ•°æ®äº¤æ¢å¤±è´¥: {str(e)}")
            return False
    
    def _synchronous_exchange(self, 
                            transaction: ExchangeTransaction,
                            data: Dict[str, Any]) -> bool:
        """åŒæ­¥äº¤æ¢"""
        try:
            # åºåˆ—åŒ–æ•°æ®
            serialized_data = self.data_serializer.serialize(data, self.exchange_config['default_format'])
            
            # é€šè¿‡ä¿¡æ¯æµå‘é€
            if transaction.exchange_type == "constraint_matrix":
                success = self.information_flow.send_constraint_matrix(
                    torch.tensor(data["constraint_matrix"]),
                    transaction.target_node,
                    Priority.HIGH
                )
            elif transaction.exchange_type == "weight_vector":
                success = self.information_flow.send_weight_vector(
                    torch.tensor(data["weight_vector"]),
                    transaction.target_node,
                    Priority.HIGH
                )
            elif transaction.exchange_type == "performance_feedback":
                success = self.information_flow.send_performance_feedback(
                    data["performance_metrics"],
                    transaction.target_node,
                    Priority.NORMAL
                )
            else:
                success = False
            
            if success:
                self.exchange_statistics['total_bytes_exchanged'] += len(serialized_data)
            
            return success
            
        except Exception as e:
            print(f"âŒ åŒæ­¥äº¤æ¢å¤±è´¥: {str(e)}")
            return False
    
    def _asynchronous_exchange(self, 
                             transaction: ExchangeTransaction,
                             data: Dict[str, Any]) -> bool:
        """å¼‚æ­¥äº¤æ¢"""
        def async_worker():
            try:
                return self._synchronous_exchange(transaction, data)
            except Exception as e:
                print(f"âŒ å¼‚æ­¥äº¤æ¢å·¥ä½œçº¿ç¨‹å¤±è´¥: {str(e)}")
                return False
        
        # å¯åŠ¨å¼‚æ­¥çº¿ç¨‹
        thread = threading.Thread(target=async_worker, daemon=True)
        thread.start()
        
        return True  # å¼‚æ­¥æ¨¡å¼ç«‹å³è¿”å›æˆåŠŸ
    
    def _buffered_exchange(self, 
                         transaction: ExchangeTransaction,
                         data: Dict[str, Any]) -> bool:
        """ç¼“å†²äº¤æ¢"""
        try:
            exchange_type = transaction.exchange_type
            
            if exchange_type in self.data_buffers:
                buffer = self.data_buffers[exchange_type]
                
                try:
                    buffer.put({
                        'transaction_id': transaction.transaction_id,
                        'data': data,
                        'timestamp': time.time()
                    }, block=False)
                    
                    return True
                    
                except queue.Full:
                    print(f"âš ï¸ ç¼“å†²åŒºæ»¡ï¼Œæ•°æ®è¢«ä¸¢å¼ƒ: {exchange_type}")
                    return False
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°å¯¹åº”ç¼“å†²åŒº: {exchange_type}")
                return False
                
        except Exception as e:
            print(f"âŒ ç¼“å†²äº¤æ¢å¤±è´¥: {str(e)}")
            return False
    
    def _streaming_exchange(self, 
                          transaction: ExchangeTransaction,
                          data: Dict[str, Any]) -> bool:
        """æµå¼äº¤æ¢"""
        try:
            # ç®€åŒ–çš„æµå¼å¤„ç†ï¼šåˆ†å—å‘é€å¤§æ•°æ®
            chunk_size = 1024  # 1KBå—
            serialized_data = self.data_serializer.serialize(data, DataFormat.BINARY)
            
            total_chunks = len(serialized_data) // chunk_size + (1 if len(serialized_data) % chunk_size > 0 else 0)
            
            for i in range(total_chunks):
                start_idx = i * chunk_size
                end_idx = min((i + 1) * chunk_size, len(serialized_data))
                chunk = serialized_data[start_idx:end_idx]
                
                chunk_data = {
                    'transaction_id': transaction.transaction_id,
                    'chunk_index': i,
                    'total_chunks': total_chunks,
                    'chunk_data': chunk.hex(),
                    'chunk_size': len(chunk)
                }
                
                # å‘é€å—
                success = self.information_flow.send_system_state(
                    chunk_data,
                    transaction.target_node,
                    Priority.NORMAL
                )
                
                if not success:
                    print(f"âŒ æµå¼äº¤æ¢å—å‘é€å¤±è´¥: {i}/{total_chunks}")
                    return False
                
                time.sleep(0.001)  # 1msé—´éš”
            
            return True
            
        except Exception as e:
            print(f"âŒ æµå¼äº¤æ¢å¤±è´¥: {str(e)}")
            return False
    
    def _update_transaction_statistics(self, 
                                     transaction: ExchangeTransaction,
                                     success: bool):
        """æ›´æ–°äº‹åŠ¡ç»Ÿè®¡"""
        self.exchange_statistics['total_exchanges'] += 1
        
        if success:
            self.exchange_statistics['successful_exchanges'] += 1
        else:
            self.exchange_statistics['failed_exchanges'] += 1
        
        if transaction.end_time:
            exchange_time = transaction.end_time - transaction.start_time
            self.exchange_statistics['average_exchange_time'] = (
                self.exchange_statistics['average_exchange_time'] * 0.9 + exchange_time * 0.1
            )
        
        # ç®¡ç†äº‹åŠ¡
        with self.transaction_lock:
            if transaction.transaction_id in self.active_transactions:
                del self.active_transactions[transaction.transaction_id]
            self.completed_transactions.append(transaction)
    
    def register_callback(self, data_type: str, callback: Callable):
        """æ³¨å†Œæ•°æ®å›è°ƒ"""
        if data_type not in self.data_callbacks:
            self.data_callbacks[data_type] = []
        
        self.data_callbacks[data_type].append(callback)
        print(f"ğŸ“ å·²æ³¨å†Œ {data_type} æ•°æ®å›è°ƒ")
    
    def process_buffered_data(self):
        """å¤„ç†ç¼“å†²åŒºæ•°æ®"""
        for exchange_type, buffer in self.data_buffers.items():
            try:
                while not buffer.empty():
                    buffered_item = buffer.get(block=False)
                    
                    # è§¦å‘å›è°ƒ
                    if exchange_type in self.data_callbacks:
                        for callback in self.data_callbacks[exchange_type]:
                            try:
                                callback(buffered_item['data'])
                            except Exception as e:
                                print(f"âš ï¸ å›è°ƒæ‰§è¡Œå¤±è´¥: {str(e)}")
                    
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ å¤„ç†ç¼“å†²æ•°æ®å¤±è´¥: {str(e)}")
    
    def get_transaction_status(self, transaction_id: str) -> Optional[Dict[str, Any]]:
        """è·å–äº‹åŠ¡çŠ¶æ€"""
        with self.transaction_lock:
            # æ£€æŸ¥æ´»è·ƒäº‹åŠ¡
            if transaction_id in self.active_transactions:
                transaction = self.active_transactions[transaction_id]
                return {
                    'transaction_id': transaction.transaction_id,
                    'status': transaction.status,
                    'exchange_type': transaction.exchange_type,
                    'start_time': transaction.start_time,
                    'elapsed_time': time.time() - transaction.start_time,
                    'retry_count': transaction.retry_count
                }
            
            # æ£€æŸ¥å®Œæˆäº‹åŠ¡
            for transaction in self.completed_transactions:
                if transaction.transaction_id == transaction_id:
                    return {
                        'transaction_id': transaction.transaction_id,
                        'status': transaction.status,
                        'exchange_type': transaction.exchange_type,
                        'start_time': transaction.start_time,
                        'end_time': transaction.end_time,
                        'total_time': transaction.end_time - transaction.start_time if transaction.end_time else None,
                        'error_message': transaction.error_message
                    }
        
        return None
    def get_exchange_statistics(self) -> Dict[str, Any]:
        """è·å–äº¤æ¢ç»Ÿè®¡ä¿¡æ¯"""
        with self.transaction_lock:
            active_count = len(self.active_transactions)
            completed_count = len(self.completed_transactions)
        
        # è®¡ç®—æˆåŠŸç‡
        total_exchanges = self.exchange_statistics['total_exchanges']
        success_rate = (self.exchange_statistics['successful_exchanges'] / total_exchanges 
                       if total_exchanges > 0 else 0.0)
        
        # ç¼“å†²åŒºçŠ¶æ€
        buffer_status = {}
        for name, buffer in self.data_buffers.items():
            buffer_status[name] = {
                'size': buffer.qsize(),
                'maxsize': buffer.maxsize,
                'usage_ratio': buffer.qsize() / buffer.maxsize if buffer.maxsize > 0 else 0.0
            }
        
        stats = {
            'exchange_id': self.exchange_id,
            'exchange_statistics': self.exchange_statistics.copy(),
            'success_rate': success_rate,
            
            'transaction_status': {
                'active_transactions': active_count,
                'completed_transactions': completed_count,
                'total_transactions': active_count + completed_count
            },
            
            'buffer_status': buffer_status,
            
            'validator_status': {
                'registered_schemas': len(self.data_validator.registered_schemas),
                'validation_errors': len(self.data_validator.validation_errors)
            },
            
            'callback_status': {
                'registered_callbacks': sum(len(callbacks) for callbacks in self.data_callbacks.values()),
                'callback_types': list(self.data_callbacks.keys())
            },
            
            'configuration': self.exchange_config.copy()
        }
        
        return stats
    
    def cleanup_completed_transactions(self, max_age: float = 3600.0):
        """æ¸…ç†å®Œæˆçš„äº‹åŠ¡"""
        current_time = time.time()
        
        with self.transaction_lock:
            # æ¸…ç†è¿‡æœŸçš„å®Œæˆäº‹åŠ¡
            self.completed_transactions = [
                t for t in self.completed_transactions 
                if t.end_time and (current_time - t.end_time) < max_age
            ]
            
            # æ¸…ç†è¶…æ—¶çš„æ´»è·ƒäº‹åŠ¡
            timeout_transactions = []
            for tid, transaction in self.active_transactions.items():
                if (current_time - transaction.start_time) > self.exchange_config['timeout']:
                    transaction.status = "timeout"
                    transaction.end_time = current_time
                    timeout_transactions.append(tid)
                    self.exchange_statistics['timeout_exchanges'] += 1
            
            for tid in timeout_transactions:
                completed_transaction = self.active_transactions.pop(tid)
                self.completed_transactions.append(completed_transaction)
        
        if timeout_transactions:
            print(f"ğŸ§¹ å·²æ¸…ç† {len(timeout_transactions)} ä¸ªè¶…æ—¶äº‹åŠ¡")
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (f"DataExchange({self.exchange_id}): "
                f"total={self.exchange_statistics['total_exchanges']}, "
                f"success={self.exchange_statistics['successful_exchanges']}, "
                f"active={len(self.active_transactions)}")
    
    def __repr__(self) -> str:
        """è¯¦ç»†å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (f"DataExchange(exchange_id='{self.exchange_id}', "
                f"total_exchanges={self.exchange_statistics['total_exchanges']}, "
                f"active_transactions={len(self.active_transactions)})")
