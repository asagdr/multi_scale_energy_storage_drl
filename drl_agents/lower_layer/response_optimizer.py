import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from collections import deque
import time
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from config.training_config import LowerLayerConfig
from config.model_config import ModelConfig

@dataclass
class ResponseMetrics:
    """å“åº”æ€§èƒ½æŒ‡æ ‡"""
    response_time: float = 0.0          # å“åº”æ—¶é—´ (s)
    settling_time: float = 0.0          # ç¨³å®šæ—¶é—´ (s)
    overshoot: float = 0.0              # è¶…è°ƒé‡ (%)
    steady_state_error: float = 0.0     # ç¨³æ€è¯¯å·® (%)
    rise_time: float = 0.0              # ä¸Šå‡æ—¶é—´ (s)
    bandwidth: float = 0.0              # å¸¦å®½ (Hz)
    phase_margin: float = 0.0           # ç›¸ä½è£•åº¦ (åº¦)
    gain_margin: float = 0.0            # å¢ç›Šè£•åº¦ (dB)

@dataclass
class OptimizationTarget:
    """ä¼˜åŒ–ç›®æ ‡"""
    target_response_time: float = 0.01  # ç›®æ ‡å“åº”æ—¶é—´ (s)
    target_overshoot: float = 5.0       # ç›®æ ‡è¶…è°ƒé‡ (%)
    target_settling_time: float = 0.05  # ç›®æ ‡ç¨³å®šæ—¶é—´ (s)
    target_bandwidth: float = 100.0     # ç›®æ ‡å¸¦å®½ (Hz)
    stability_requirement: float = 0.8  # ç¨³å®šæ€§è¦æ±‚ [0,1]

class ResponsePredictor(nn.Module):
    """å“åº”æ€§èƒ½é¢„æµ‹å™¨"""
    
    def __init__(self, input_dim: int = 15, hidden_dim: int = 64):
        super(ResponsePredictor, self).__init__()
        
        # å“åº”æ—¶é—´é¢„æµ‹
        self.response_time_predictor = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.LayerNorm(hidden_dim),
            nn.Dropout(0.1),
            
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()  # è¾“å‡º0-1ï¼Œè¡¨ç¤ºå½’ä¸€åŒ–çš„å“åº”æ—¶é—´
        )
        
        # ç¨³å®šæ€§é¢„æµ‹
        self.stability_predictor = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.LayerNorm(hidden_dim),
            nn.Dropout(0.1),
            
            nn.Linear(hidden_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 3),  # [overshoot, settling_time, steady_state_error]
        )
        
        # æ€§èƒ½ç»¼åˆè¯„ä¼°
        self.performance_evaluator = nn.Sequential(
            nn.Linear(input_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Sigmoid()  # ç»¼åˆæ€§èƒ½è¯„åˆ† [0,1]
        )
    
    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        """å‰å‘ä¼ æ’­"""
        response_time = self.response_time_predictor(x) * 0.1  # 0-100ms
        stability_metrics = self.stability_predictor(x)
        performance_score = self.performance_evaluator(x)
        
        return {
            'predicted_response_time': response_time,
            'predicted_overshoot': torch.abs(stability_metrics[:, 0:1]) * 20,  # 0-20%
            'predicted_settling_time': torch.sigmoid(stability_metrics[:, 1:2]) * 0.2,  # 0-200ms
            'predicted_steady_error': torch.sigmoid(stability_metrics[:, 2:3]) * 5,  # 0-5%
            'performance_score': performance_score
        }

class AdaptiveController:
    """è‡ªé€‚åº”æ§åˆ¶å™¨å‚æ•°è°ƒèŠ‚"""
    
    def __init__(self):
        # æ§åˆ¶å™¨å‚æ•°èŒƒå›´
        self.param_ranges = {
            'kp': (0.1, 10.0),
            'ki': (0.01, 2.0),
            'kd': (0.001, 0.5),
            'filter_freq': (10.0, 1000.0),    # Hz
            'damping_ratio': (0.3, 1.5)
        }
        
        # å½“å‰å‚æ•°
        self.current_params = {
            'kp': 2.0,
            'ki': 0.5,
            'kd': 0.1,
            'filter_freq': 100.0,
            'damping_ratio': 0.707
        }
        
        # å‚æ•°è°ƒæ•´å†å²
        self.param_history = deque(maxlen=100)
        
        # æ€§èƒ½å†å²
        self.performance_history = deque(maxlen=100)
    
    def adapt_parameters(self, 
                        current_metrics: ResponseMetrics,
                        target: OptimizationTarget) -> Dict[str, float]:
        """è‡ªé€‚åº”è°ƒæ•´æ§åˆ¶å™¨å‚æ•°"""
        # è®¡ç®—æ€§èƒ½åå·®
        response_error = current_metrics.response_time - target.target_response_time
        overshoot_error = current_metrics.overshoot - target.target_overshoot
        settling_error = current_metrics.settling_time - target.target_settling_time
        
        # å‚æ•°è°ƒæ•´ç­–ç•¥
        param_adjustments = {}
        
        # æ¯”ä¾‹å¢ç›Šè°ƒæ•´
        if abs(response_error) > 0.01:  # å“åº”æ—¶é—´è¯¯å·®è¶…è¿‡10ms
            if response_error > 0:  # å“åº”å¤ªæ…¢
                param_adjustments['kp'] = min(self.param_ranges['kp'][1], 
                                            self.current_params['kp'] * 1.1)
            else:  # å“åº”å¤ªå¿«ï¼Œå¯èƒ½ä¸ç¨³å®š
                param_adjustments['kp'] = max(self.param_ranges['kp'][0], 
                                            self.current_params['kp'] * 0.95)
        
        # ç§¯åˆ†å¢ç›Šè°ƒæ•´
        if abs(current_metrics.steady_state_error) > 1.0:  # ç¨³æ€è¯¯å·®è¶…è¿‡1%
            param_adjustments['ki'] = min(self.param_ranges['ki'][1], 
                                        self.current_params['ki'] * 1.05)
        elif abs(current_metrics.steady_state_error) < 0.1:  # ç¨³æ€è¯¯å·®å¾ˆå°
            param_adjustments['ki'] = max(self.param_ranges['ki'][0], 
                                        self.current_params['ki'] * 0.98)
        
        # å¾®åˆ†å¢ç›Šè°ƒæ•´
        if overshoot_error > 2.0:  # è¶…è°ƒè¿‡å¤§
            param_adjustments['kd'] = min(self.param_ranges['kd'][1], 
                                        self.current_params['kd'] * 1.1)
        elif overshoot_error < -2.0:  # è¶…è°ƒè¿‡å°ï¼Œå¯èƒ½å“åº”æ…¢
            param_adjustments['kd'] = max(self.param_ranges['kd'][0], 
                                        self.current_params['kd'] * 0.95)
        
        # æ›´æ–°å‚æ•°
        for param, new_value in param_adjustments.items():
            self.current_params[param] = new_value
        
        # è®°å½•å†å²
        self.param_history.append(self.current_params.copy())
        self.performance_history.append({
            'response_time': current_metrics.response_time,
            'overshoot': current_metrics.overshoot,
            'settling_time': current_metrics.settling_time,
            'steady_state_error': current_metrics.steady_state_error
        })
        
        return self.current_params.copy()
    
    def get_optimization_trend(self) -> str:
        """è·å–ä¼˜åŒ–è¶‹åŠ¿"""
        if len(self.performance_history) < 10:
            return "insufficient_data"
        
        recent_performance = list(self.performance_history)[-10:]
        
        # è®¡ç®—å“åº”æ—¶é—´è¶‹åŠ¿
        response_times = [p['response_time'] for p in recent_performance]
        response_trend = np.polyfit(range(len(response_times)), response_times, 1)[0]
        
        # è®¡ç®—è¶…è°ƒé‡è¶‹åŠ¿
        overshoots = [p['overshoot'] for p in recent_performance]
        overshoot_trend = np.polyfit(range(len(overshoots)), overshoots, 1)[0]
        
        if response_trend < -0.001 and overshoot_trend < 0.5:
            return "improving"
        elif response_trend > 0.001 or overshoot_trend > 1.0:
            return "degrading"
        else:
            return "stable"

class ResponseOptimizer(nn.Module):
    """
    å“åº”ä¼˜åŒ–å™¨
    ä¼˜åŒ–æ§åˆ¶ç³»ç»Ÿçš„åŠ¨æ€å“åº”æ€§èƒ½ï¼šå“åº”æ—¶é—´ã€è¶…è°ƒé‡ã€ç¨³å®šæ€§
    """
    
    def __init__(self,
                 config: LowerLayerConfig,
                 model_config: ModelConfig,
                 optimizer_id: str = "ResponseOptimizer_001"):
        """
        åˆå§‹åŒ–å“åº”ä¼˜åŒ–å™¨
        
        Args:
            config: ä¸‹å±‚é…ç½®
            model_config: æ¨¡å‹é…ç½®
            optimizer_id: ä¼˜åŒ–å™¨ID
        """
        super(ResponseOptimizer, self).__init__()
        
        self.config = config
        self.model_config = model_config
        self.optimizer_id = optimizer_id
        
        # === ç¥ç»ç½‘ç»œé¢„æµ‹å™¨ ===
        self.response_predictor = ResponsePredictor(
            input_dim=15,  # ç³»ç»ŸçŠ¶æ€ + æ§åˆ¶å‚æ•°
            hidden_dim=64
        )
        
        # === è‡ªé€‚åº”æ§åˆ¶å™¨ ===
        self.adaptive_controller = AdaptiveController()
        
        # === ä¼˜åŒ–ç›®æ ‡ ===
        self.optimization_target = OptimizationTarget()
        
        # === å“åº”ç‰¹æ€§åˆ†æ ===
        self.step_response_data = deque(maxlen=1000)
        self.frequency_response_data = deque(maxlen=100)
        
        # === æ€§èƒ½åŸºå‡† ===
        self.performance_baseline = {
            'response_time': 0.05,      # 50msåŸºå‡†
            'overshoot': 10.0,          # 10%åŸºå‡†
            'settling_time': 0.1,       # 100msåŸºå‡†
            'bandwidth': 50.0           # 50HzåŸºå‡†
        }
        
        # === ä¼˜åŒ–å†å² ===
        self.optimization_history: List[Dict] = []
        self.performance_improvements = []
        
        # === ç»Ÿè®¡ä¿¡æ¯ ===
        self.total_optimizations = 0
        self.successful_optimizations = 0
        self.response_measurements = 0
        
        print(f"âœ… å“åº”ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ: {optimizer_id}")
        print(f"   ç›®æ ‡å“åº”æ—¶é—´: {self.optimization_target.target_response_time*1000:.1f}ms")
        print(f"   ç›®æ ‡è¶…è°ƒé‡: {self.optimization_target.target_overshoot:.1f}%")
    
    def measure_step_response(self, 
                            input_signal: np.ndarray,
                            output_signal: np.ndarray,
                            time_vector: np.ndarray) -> ResponseMetrics:
        """
        æµ‹é‡é˜¶è·ƒå“åº”ç‰¹æ€§
        
        Args:
            input_signal: è¾“å…¥ä¿¡å·
            output_signal: è¾“å‡ºä¿¡å·
            time_vector: æ—¶é—´å‘é‡
            
        Returns:
            å“åº”æ€§èƒ½æŒ‡æ ‡
        """
        self.response_measurements += 1
        
        # æŸ¥æ‰¾é˜¶è·ƒå¼€å§‹ç‚¹
        step_start_idx = self._find_step_start(input_signal)
        if step_start_idx == -1:
            return ResponseMetrics()  # è¿”å›é»˜è®¤å€¼
        
        # æå–é˜¶è·ƒå“åº”éƒ¨åˆ†
        step_input = input_signal[step_start_idx:]
        step_output = output_signal[step_start_idx:]
        step_time = time_vector[step_start_idx:] - time_vector[step_start_idx]
        
        # è®¡ç®—ç¨³æ€å€¼
        steady_state_value = np.mean(step_output[-50:]) if len(step_output) > 50 else step_output[-1]
        initial_value = step_output[0]
        step_magnitude = steady_state_value - initial_value
        
        if abs(step_magnitude) < 1e-6:
            return ResponseMetrics()
        
        # === 1. å“åº”æ—¶é—´ï¼ˆ10%-90%ä¸Šå‡æ—¶é—´ï¼‰ ===
        response_time = self._calculate_response_time(step_output, step_time, 
                                                    initial_value, steady_state_value)
        
        # === 2. ä¸Šå‡æ—¶é—´ï¼ˆ0%-100%ï¼‰ ===
        rise_time = self._calculate_rise_time(step_output, step_time, 
                                            initial_value, steady_state_value)
        
        # === 3. è¶…è°ƒé‡ ===
        overshoot = self._calculate_overshoot(step_output, steady_state_value, step_magnitude)
        
        # === 4. ç¨³å®šæ—¶é—´ï¼ˆÂ±2%è¯¯å·®å¸¦ï¼‰ ===
        settling_time = self._calculate_settling_time(step_output, step_time, 
                                                    steady_state_value, step_magnitude)
        
        # === 5. ç¨³æ€è¯¯å·® ===
        target_value = np.mean(step_input[-50:]) if len(step_input) > 50 else step_input[-1]
        steady_state_error = abs(steady_state_value - target_value) / abs(target_value) * 100.0 if target_value != 0 else 0.0
        
        # === 6. é¢‘åŸŸç‰¹æ€§ï¼ˆç®€åŒ–ä¼°ç®—ï¼‰ ===
        bandwidth = self._estimate_bandwidth(step_output, step_time)
        
        metrics = ResponseMetrics(
            response_time=response_time,
            rise_time=rise_time,
            overshoot=overshoot,
            settling_time=settling_time,
            steady_state_error=steady_state_error,
            bandwidth=bandwidth,
            phase_margin=60.0,  # ç®€åŒ–å‡è®¾
            gain_margin=10.0    # ç®€åŒ–å‡è®¾
        )
        
        # è®°å½•æ•°æ®
        self.step_response_data.append({
            'time': step_time.copy(),
            'output': step_output.copy(),
            'metrics': metrics,
            'timestamp': time.time()
        })
        
        return metrics
    
    def predict_response_performance(self, 
                                   system_state: Dict[str, Any],
                                   control_params: Dict[str, float]) -> Dict[str, float]:
        """
        é¢„æµ‹å“åº”æ€§èƒ½
        
        Args:
            system_state: ç³»ç»ŸçŠ¶æ€
            control_params: æ§åˆ¶å‚æ•°
            
        Returns:
            é¢„æµ‹çš„æ€§èƒ½æŒ‡æ ‡
        """
        # å‡†å¤‡è¾“å…¥ç‰¹å¾
        input_features = self._prepare_prediction_input(system_state, control_params)
        
        # ç¥ç»ç½‘ç»œé¢„æµ‹
        self.response_predictor.eval()
        with torch.no_grad():
            predictions = self.response_predictor(input_features)
        
        # è§£æé¢„æµ‹ç»“æœ
        predicted_performance = {
            'response_time': predictions['predicted_response_time'].item(),
            'overshoot': predictions['predicted_overshoot'].item(),
            'settling_time': predictions['predicted_settling_time'].item(),
            'steady_state_error': predictions['predicted_steady_error'].item(),
            'performance_score': predictions['performance_score'].item()
        }
        
        return predicted_performance
    
    def optimize_response(self, 
                         current_metrics: ResponseMetrics,
                         system_state: Dict[str, Any],
                         constraints: Optional[Dict[str, float]] = None) -> Dict[str, Any]:
        """
        ä¼˜åŒ–å“åº”æ€§èƒ½
        
        Args:
            current_metrics: å½“å‰æ€§èƒ½æŒ‡æ ‡
            system_state: ç³»ç»ŸçŠ¶æ€
            constraints: ä¼˜åŒ–çº¦æŸ
            
        Returns:
            ä¼˜åŒ–ç»“æœ
        """
        self.total_optimizations += 1
        
        # === 1. æ€§èƒ½è¯„ä¼° ===
        performance_score = self._evaluate_performance(current_metrics)
        
        # === 2. è‡ªé€‚åº”å‚æ•°è°ƒæ•´ ===
        optimized_params = self.adaptive_controller.adapt_parameters(
            current_metrics, self.optimization_target
        )
        
        # === 3. é¢„æµ‹ä¼˜åŒ–æ•ˆæœ ===
        predicted_performance = self.predict_response_performance(
            system_state, optimized_params
        )
        
        # === 4. çº¦æŸæ£€æŸ¥ ===
        if constraints:
            optimized_params = self._apply_optimization_constraints(optimized_params, constraints)
        
        # === 5. ä¼˜åŒ–éªŒè¯ ===
        optimization_success = self._validate_optimization(
            current_metrics, predicted_performance
        )
        
        if optimization_success:
            self.successful_optimizations += 1
        
        # === 6. è®°å½•ä¼˜åŒ–å†å² ===
        optimization_record = {
            'timestamp': time.time(),
            'current_performance': {
                'response_time': current_metrics.response_time,
                'overshoot': current_metrics.overshoot,
                'settling_time': current_metrics.settling_time,
                'performance_score': performance_score
            },
            'optimized_params': optimized_params.copy(),
            'predicted_performance': predicted_performance.copy(),
            'optimization_success': optimization_success,
            'improvement_ratio': self._calculate_improvement_ratio(current_metrics, predicted_performance)
        }
        
        self.optimization_history.append(optimization_record)
        
        # ç»´æŠ¤å†å²é•¿åº¦
        if len(self.optimization_history) > 1000:
            self.optimization_history.pop(0)
        
        # === 7. æ„å»ºç»“æœ ===
        result = {
            'optimized_parameters': optimized_params,
            'predicted_performance': predicted_performance,
            'current_performance_score': performance_score,
            'optimization_success': optimization_success,
            'performance_improvement': optimization_record['improvement_ratio'],
            'optimization_trend': self.adaptive_controller.get_optimization_trend(),
            'recommendations': self._generate_optimization_recommendations(current_metrics)
        }
        
        return result
    
    def _find_step_start(self, input_signal: np.ndarray) -> int:
        """æŸ¥æ‰¾é˜¶è·ƒå¼€å§‹ç‚¹"""
        # ç®€åŒ–å®ç°ï¼šæŸ¥æ‰¾ä¿¡å·å˜åŒ–æœ€å¤§çš„ç‚¹
        if len(input_signal) < 10:
            return -1
        
        signal_diff = np.diff(input_signal)
        max_change_idx = np.argmax(np.abs(signal_diff))
        
        # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆé˜¶è·ƒ
        if abs(signal_diff[max_change_idx]) > 0.1 * np.std(input_signal):
            return max_change_idx
        else:
            return 0  # é»˜è®¤ä»å¼€å§‹
    
    def _calculate_response_time(self, 
                               output: np.ndarray, 
                               time: np.ndarray,
                               initial_value: float, 
                               final_value: float) -> float:
        """è®¡ç®—10%-90%å“åº”æ—¶é—´"""
        step_magnitude = final_value - initial_value
        if abs(step_magnitude) < 1e-6:
            return 0.0
        
        # 10%å’Œ90%é˜ˆå€¼
        threshold_10 = initial_value + 0.1 * step_magnitude
        threshold_90 = initial_value + 0.9 * step_magnitude
        
        # æŸ¥æ‰¾äº¤è¶Šç‚¹
        time_10 = None
        time_90 = None
        
        for i, val in enumerate(output):
            if time_10 is None and ((step_magnitude > 0 and val >= threshold_10) or 
                                   (step_magnitude < 0 and val <= threshold_10)):
                time_10 = time[i]
            
            if time_90 is None and ((step_magnitude > 0 and val >= threshold_90) or 
                                   (step_magnitude < 0 and val <= threshold_90)):
                time_90 = time[i]
                break
        
        if time_10 is not None and time_90 is not None:
            return time_90 - time_10
        else:
            return time[-1] if len(time) > 0 else 0.0
    
    def _calculate_rise_time(self, 
                           output: np.ndarray, 
                           time: np.ndarray,
                           initial_value: float, 
                           final_value: float) -> float:
        """è®¡ç®—ä¸Šå‡æ—¶é—´"""
        step_magnitude = final_value - initial_value
        if abs(step_magnitude) < 1e-6:
            return 0.0
        
        threshold_100 = initial_value + 0.95 * step_magnitude  # 95%é˜ˆå€¼
        
        for i, val in enumerate(output):
            if ((step_magnitude > 0 and val >= threshold_100) or 
                (step_magnitude < 0 and val <= threshold_100)):
                return time[i] - time[0]
        
        return time[-1] - time[0] if len(time) > 1 else 0.0
    
    def _calculate_overshoot(self, 
                           output: np.ndarray, 
                           steady_state: float, 
                           step_magnitude: float) -> float:
        """è®¡ç®—è¶…è°ƒé‡"""
        if abs(step_magnitude) < 1e-6:
            return 0.0
        
        if step_magnitude > 0:
            max_value = np.max(output)
            overshoot = (max_value - steady_state) / step_magnitude * 100.0
        else:
            min_value = np.min(output)
            overshoot = (steady_state - min_value) / abs(step_magnitude) * 100.0
        
        return max(0.0, overshoot)
    
    def _calculate_settling_time(self, 
                               output: np.ndarray, 
                               time: np.ndarray,
                               steady_state: float, 
                               step_magnitude: float) -> float:
        """è®¡ç®—Â±2%ç¨³å®šæ—¶é—´"""
        if abs(step_magnitude) < 1e-6 or len(output) < 10:
            return 0.0
        
        tolerance = 0.02 * abs(step_magnitude)  # Â±2%è¯¯å·®å¸¦
        
        # ä»åå¾€å‰æœç´¢ï¼Œæ‰¾åˆ°æœ€åä¸€æ¬¡è¶…å‡ºè¯¯å·®å¸¦çš„æ—¶é—´
        for i in range(len(output) - 1, -1, -1):
            if abs(output[i] - steady_state) > tolerance:
                if i < len(time) - 1:
                    return time[i + 1] - time[0]
                else:
                    return time[-1] - time[0]
        
        return time[min(10, len(time) - 1)] - time[0]  # æœ€å°‘10ä¸ªé‡‡æ ·ç‚¹
    
    def _estimate_bandwidth(self, output: np.ndarray, time: np.ndarray) -> float:
        """ä¼°ç®—å¸¦å®½"""
        if len(output) < 10 or len(time) < 10:
            return 0.0
        
        # ç®€åŒ–æ–¹æ³•ï¼šåŸºäºå“åº”é€Ÿåº¦ä¼°ç®—
        dt = time[1] - time[0] if len(time) > 1 else 0.01
        
        # è®¡ç®—ä¿¡å·å˜åŒ–ç‡
        signal_diff = np.diff(output)
        max_rate = np.max(np.abs(signal_diff)) / dt
        
        # ä¼°ç®—å¸¦å®½ï¼ˆç»éªŒå…¬å¼ï¼‰
        bandwidth = max_rate / (2 * np.pi * np.std(output)) if np.std(output) > 1e-6 else 0.0
        
        return min(1000.0, max(1.0, bandwidth))  # é™åˆ¶åœ¨åˆç†èŒƒå›´
    
    def _prepare_prediction_input(self, 
                                system_state: Dict[str, Any],
                                control_params: Dict[str, float]) -> torch.Tensor:
        """å‡†å¤‡é¢„æµ‹è¾“å…¥ç‰¹å¾"""
        features = []
        
        # ç³»ç»ŸçŠ¶æ€ç‰¹å¾
        features.extend([
            system_state.get('soc', 50.0) / 100.0,
            system_state.get('temperature', 25.0) / 60.0,
            system_state.get('voltage', 3.4) / 4.2,
            system_state.get('current', 0.0) / 200.0,
            system_state.get('power', 0.0) / 50000.0,
            system_state.get('load_disturbance', 0.0) / 1000.0
        ])
        
        # æ§åˆ¶å‚æ•°ç‰¹å¾
        features.extend([
            control_params.get('kp', 1.0) / 10.0,
            control_params.get('ki', 0.1) / 2.0,
            control_params.get('kd', 0.01) / 0.5,
            control_params.get('filter_freq', 100.0) / 1000.0,
            control_params.get('damping_ratio', 0.707) / 2.0
        ])
        
        # å†å²æ€§èƒ½ç‰¹å¾
        if len(self.step_response_data) > 0:
            recent_data = list(self.step_response_data)[-5:]
            avg_response_time = np.mean([data['metrics'].response_time for data in recent_data])
            avg_overshoot = np.mean([data['metrics'].overshoot for data in recent_data])
            features.extend([
                avg_response_time / 0.1,
                avg_overshoot / 20.0
            ])
        else:
            features.extend([0.5, 0.5])
        
        # ä¼˜åŒ–è¶‹åŠ¿ç‰¹å¾
        trend = self.adaptive_controller.get_optimization_trend()
        trend_encoding = {'improving': 1.0, 'stable': 0.5, 'degrading': 0.0, 'insufficient_data': 0.5}
        features.append(trend_encoding.get(trend, 0.5))
        
        return torch.tensor(features, dtype=torch.float32).unsqueeze(0)
    
    def _evaluate_performance(self, metrics: ResponseMetrics) -> float:
        """è¯„ä¼°æ€§èƒ½å¾—åˆ†"""
        # å“åº”æ—¶é—´å¾—åˆ†
        response_score = max(0.0, 1.0 - metrics.response_time / 0.1)  # 100msä¸º0åˆ†
        
        # è¶…è°ƒé‡å¾—åˆ†
        overshoot_score = max(0.0, 1.0 - metrics.overshoot / 20.0)  # 20%ä¸º0åˆ†
        
        # ç¨³å®šæ—¶é—´å¾—åˆ†
        settling_score = max(0.0, 1.0 - metrics.settling_time / 0.2)  # 200msä¸º0åˆ†
        
        # ç¨³æ€è¯¯å·®å¾—åˆ†
        error_score = max(0.0, 1.0 - metrics.steady_state_error / 5.0)  # 5%ä¸º0åˆ†
        
        # åŠ æƒç»¼åˆå¾—åˆ†
        total_score = (0.3 * response_score + 0.3 * overshoot_score + 
                      0.25 * settling_score + 0.15 * error_score)
        
        return total_score
    
    def _apply_optimization_constraints(self, 
                                      params: Dict[str, float],
                                      constraints: Dict[str, float]) -> Dict[str, float]:
        """åº”ç”¨ä¼˜åŒ–çº¦æŸ"""
        constrained_params = params.copy()
        
        # å“åº”æ—¶é—´çº¦æŸ
        max_response_time = constraints.get('max_response_time', 0.1)
        if params.get('kp', 0) < 0.5:  # Kpå¤ªå°å¯èƒ½å¯¼è‡´å“åº”æ…¢
            constrained_params['kp'] = max(0.5, params['kp'])
        
        # ç¨³å®šæ€§çº¦æŸ
        max_kp = constraints.get('max_kp', 10.0)
        constrained_params['kp'] = min(max_kp, constrained_params['kp'])
        
        # ç§¯åˆ†é¥±å’Œçº¦æŸ
        max_ki = constraints.get('max_ki', 2.0)
        constrained_params['ki'] = min(max_ki, constrained_params['ki'])
        
        # å™ªå£°æ•æ„Ÿæ€§çº¦æŸ
        max_kd = constraints.get('max_kd', 0.5)
        constrained_params['kd'] = min(max_kd, constrained_params['kd'])
        
        return constrained_params
    
    def _validate_optimization(self, 
                             current_metrics: ResponseMetrics,
                             predicted_performance: Dict[str, float]) -> bool:
        """éªŒè¯ä¼˜åŒ–æ•ˆæœ"""
        # æ€§èƒ½æ”¹å–„éªŒè¯
        current_score = self._evaluate_performance(current_metrics)
        predicted_score = predicted_performance.get('performance_score', 0.0)
        
        # å“åº”æ—¶é—´æ”¹å–„
        response_improvement = current_metrics.response_time - predicted_performance.get('response_time', current_metrics.response_time)
        
        # è¶…è°ƒé‡æ”¹å–„
        overshoot_improvement = current_metrics.overshoot - predicted_performance.get('overshoot', current_metrics.overshoot)
        
        # éªŒè¯æ¡ä»¶
        conditions = [
            predicted_score > current_score + 0.05,  # æ€§èƒ½å¾—åˆ†è‡³å°‘æå‡5%
            response_improvement > -0.01,             # å“åº”æ—¶é—´ä¸èƒ½æ¶åŒ–è¶…è¿‡10ms
            overshoot_improvement > -2.0,             # è¶…è°ƒé‡ä¸èƒ½æ¶åŒ–è¶…è¿‡2%
            predicted_performance.get('response_time', 0.1) < 0.1,  # å“åº”æ—¶é—´åœ¨100mså†…
            predicted_performance.get('overshoot', 20.0) < 15.0     # è¶…è°ƒé‡åœ¨15%å†…
        ]
        
        return all(conditions)
    
    def _calculate_improvement_ratio(self, 
                                   current_metrics: ResponseMetrics,
                                   predicted_performance: Dict[str, float]) -> float:
        """è®¡ç®—æ”¹å–„æ¯”ä¾‹"""
        current_score = self._evaluate_performance(current_metrics)
        predicted_score = predicted_performance.get('performance_score', current_score)
        
        if current_score > 0:
            improvement = (predicted_score - current_score) / current_score
        else:
            improvement = predicted_score
        
        return improvement
    
    def _generate_optimization_recommendations(self, metrics: ResponseMetrics) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # å“åº”æ—¶é—´å»ºè®®
        if metrics.response_time > self.optimization_target.target_response_time * 2:
            recommendations.append("å¢åŠ æ¯”ä¾‹å¢ç›Šä»¥æé«˜å“åº”é€Ÿåº¦")
        elif metrics.response_time < self.optimization_target.target_response_time * 0.5:
            recommendations.append("é€‚åº¦é™ä½æ¯”ä¾‹å¢ç›Šä»¥é¿å…è¿‡å¿«å“åº”")
        
        # è¶…è°ƒé‡å»ºè®®
        if metrics.overshoot > self.optimization_target.target_overshoot * 1.5:
            recommendations.append("å¢åŠ å¾®åˆ†å¢ç›Šæˆ–é™ä½æ¯”ä¾‹å¢ç›Šä»¥å‡å°‘è¶…è°ƒ")
        elif metrics.overshoot < self.optimization_target.target_overshoot * 0.3:
            recommendations.append("å¯é€‚åº¦å¢åŠ æ¯”ä¾‹å¢ç›Šä»¥æ”¹å–„å“åº”")
        
        # ç¨³å®šæ—¶é—´å»ºè®®
        if metrics.settling_time > self.optimization_target.target_settling_time * 2:
            recommendations.append("è°ƒæ•´é˜»å°¼æ¯”æˆ–å¢åŠ å¸¦å®½ä»¥åŠ å¿«ç¨³å®š")
        
        # ç¨³æ€è¯¯å·®å»ºè®®
        if metrics.steady_state_error > 2.0:
            recommendations.append("å¢åŠ ç§¯åˆ†å¢ç›Šä»¥å‡å°‘ç¨³æ€è¯¯å·®")
        
        # ç³»ç»Ÿç¨³å®šæ€§å»ºè®®
        if metrics.phase_margin < 30.0:
            recommendations.append("é™ä½å¢ç›Šæˆ–å¢åŠ ç›¸ä½è¡¥å¿ä»¥æé«˜ç¨³å®šè£•åº¦")
        
        if not recommendations:
            recommendations.append("å½“å‰æ€§èƒ½è‰¯å¥½ï¼Œç»´æŒç°æœ‰å‚æ•°")
        
        return recommendations
    
    def tune_controller_online(self, 
                             performance_data: List[ResponseMetrics],
                             adaptation_rate: float = 0.1) -> Dict[str, float]:
        """åœ¨çº¿æ§åˆ¶å™¨è°ƒèŠ‚"""
        if len(performance_data) < 5:
            return self.adaptive_controller.current_params.copy()
        
        # è®¡ç®—æ€§èƒ½è¶‹åŠ¿
        recent_scores = [self._evaluate_performance(metrics) for metrics in performance_data[-10:]]
        performance_trend = np.polyfit(range(len(recent_scores)), recent_scores, 1)[0]
        
        # è®¡ç®—å¹³å‡æ€§èƒ½æŒ‡æ ‡
        avg_response_time = np.mean([m.response_time for m in performance_data[-5:]])
        avg_overshoot = np.mean([m.overshoot for m in performance_data[-5:]])
        avg_settling_time = np.mean([m.settling_time for m in performance_data[-5:]])
        
        # è‡ªé€‚åº”è°ƒèŠ‚
        current_params = self.adaptive_controller.current_params.copy()
        
        if performance_trend < -0.05:  # æ€§èƒ½ä¸‹é™
            # æ›´ä¿å®ˆçš„è°ƒèŠ‚
            if avg_overshoot > self.optimization_target.target_overshoot:
                current_params['kp'] *= (1.0 - adaptation_rate)
                current_params['kd'] *= (1.0 + adaptation_rate)
            
            if avg_response_time > self.optimization_target.target_response_time:
                current_params['kp'] *= (1.0 + adaptation_rate * 0.5)
        
        elif performance_trend > 0.05:  # æ€§èƒ½æå‡
            # ç»§ç»­ä¼˜åŒ–
            if avg_response_time > self.optimization_target.target_response_time:
                current_params['kp'] *= (1.0 + adaptation_rate)
            
            if avg_settling_time > self.optimization_target.target_settling_time:
                current_params['ki'] *= (1.0 + adaptation_rate * 0.5)
        
        # åº”ç”¨å‚æ•°èŒƒå›´é™åˆ¶
        for param, value in current_params.items():
            if param in self.adaptive_controller.param_ranges:
                min_val, max_val = self.adaptive_controller.param_ranges[param]
                current_params[param] = np.clip(value, min_val, max_val)
        
        # æ›´æ–°æ§åˆ¶å™¨å‚æ•°
        self.adaptive_controller.current_params = current_params
        
        return current_params
    
    def analyze_frequency_response(self, 
                                 frequencies: np.ndarray,
                                 magnitude_response: np.ndarray,
                                 phase_response: np.ndarray) -> Dict[str, float]:
        """åˆ†æé¢‘ç‡å“åº”ç‰¹æ€§"""
        try:
            # è®¡ç®—å¸¦å®½ï¼ˆ-3dBç‚¹ï¼‰
            mag_db = 20 * np.log10(np.abs(magnitude_response) + 1e-10)
            dc_gain_db = mag_db[0]
            bandwidth_idx = np.where(mag_db <= dc_gain_db - 3.0)[0]
            bandwidth = frequencies[bandwidth_idx[0]] if len(bandwidth_idx) > 0 else frequencies[-1]
            
            # è®¡ç®—ç›¸ä½è£•åº¦
            # æŸ¥æ‰¾å¢ç›Šäº¤è¶Šé¢‘ç‡ï¼ˆ|H(jw)| = 1ï¼‰
            gain_crossover_idx = np.argmin(np.abs(magnitude_response - 1.0))
            phase_margin = 180.0 + phase_response[gain_crossover_idx]
            
            # è®¡ç®—å¢ç›Šè£•åº¦
            # æŸ¥æ‰¾ç›¸ä½äº¤è¶Šé¢‘ç‡ï¼ˆphase = -180Â°ï¼‰
            phase_crossover_idx = np.argmin(np.abs(phase_response + 180.0))
            gain_margin_db = -mag_db[phase_crossover_idx]
            
            # ä¼°ç®—é˜»å°¼æ¯”
            # åŸºäºé¢‘ç‡å“åº”çš„å³°å€¼
            peak_magnitude = np.max(magnitude_response)
            if peak_magnitude > 1.0:
                damping_ratio = 1.0 / (2.0 * peak_magnitude)
            else:
                damping_ratio = 0.707  # é»˜è®¤å€¼
            
            frequency_analysis = {
                'bandwidth': bandwidth,
                'phase_margin': phase_margin,
                'gain_margin': gain_margin_db,
                'damping_ratio': damping_ratio,
                'peak_magnitude': peak_magnitude,
                'dc_gain': magnitude_response[0],
                'stability_measure': min(phase_margin / 60.0, gain_margin_db / 10.0)  # å½’ä¸€åŒ–ç¨³å®šæ€§æŒ‡æ ‡
            }
            
            # è®°å½•é¢‘ç‡å“åº”æ•°æ®
            self.frequency_response_data.append({
                'frequencies': frequencies.copy(),
                'magnitude': magnitude_response.copy(),
                'phase': phase_response.copy(),
                'analysis': frequency_analysis,
                'timestamp': time.time()
            })
            
            return frequency_analysis
            
        except Exception as e:
            print(f"âš ï¸ é¢‘ç‡å“åº”åˆ†æå¤±è´¥: {str(e)}")
            return {
                'bandwidth': 50.0,
                'phase_margin': 45.0,
                'gain_margin': 10.0,
                'damping_ratio': 0.707,
                'peak_magnitude': 1.0,
                'dc_gain': 1.0,
                'stability_measure': 0.75
            }
    
    def generate_optimal_trajectory(self, 
                                  start_state: np.ndarray,
                                  target_state: np.ndarray,
                                  time_horizon: float) -> Dict[str, np.ndarray]:
        """ç”Ÿæˆæœ€ä¼˜è½¨è¿¹"""
        # ç®€åŒ–çš„è½¨è¿¹ç”Ÿæˆï¼ˆå®é™…åº”ç”¨ä¸­å¯ä½¿ç”¨MPCæˆ–è½¨è¿¹ä¼˜åŒ–ï¼‰
        num_points = int(time_horizon / 0.01)  # 10msé‡‡æ ·
        time_vector = np.linspace(0, time_horizon, num_points)
        
        # ä½¿ç”¨5æ¬¡å¤šé¡¹å¼ç”Ÿæˆå¹³æ»‘è½¨è¿¹
        # ç¡®ä¿ä½ç½®ã€é€Ÿåº¦ã€åŠ é€Ÿåº¦è¿ç»­
        trajectory = np.zeros((num_points, len(start_state)))
        
        for i in range(len(start_state)):
            # 5æ¬¡å¤šé¡¹å¼ç³»æ•°è®¡ç®—
            # è¾¹ç•Œæ¡ä»¶ï¼šèµ·å§‹å’Œç»ˆæ­¢çš„ä½ç½®ã€é€Ÿåº¦ã€åŠ é€Ÿåº¦
            a0 = start_state[i]
            a1 = 0.0  # èµ·å§‹é€Ÿåº¦ä¸º0
            a2 = 0.0  # èµ·å§‹åŠ é€Ÿåº¦ä¸º0
            
            # ç»ˆæ­¢æ¡ä»¶
            a3 = 10 * (target_state[i] - start_state[i]) / (time_horizon ** 3)
            a4 = -15 * (target_state[i] - start_state[i]) / (time_horizon ** 4)
            a5 = 6 * (target_state[i] - start_state[i]) / (time_horizon ** 5)
            
            # ç”Ÿæˆè½¨è¿¹
            for j, t in enumerate(time_vector):
                trajectory[j, i] = (a0 + a1 * t + a2 * t**2 + 
                                  a3 * t**3 + a4 * t**4 + a5 * t**5)
        
        # è®¡ç®—é€Ÿåº¦å’ŒåŠ é€Ÿåº¦è½¨è¿¹
        velocity = np.gradient(trajectory, axis=0) / 0.01
        acceleration = np.gradient(velocity, axis=0) / 0.01
        
        return {
            'time': time_vector,
            'position': trajectory,
            'velocity': velocity,
            'acceleration': acceleration,
            'jerk': np.gradient(acceleration, axis=0) / 0.01
        }
    
    def evaluate_optimization_effectiveness(self, window_size: int = 100) -> Dict[str, float]:
        """è¯„ä¼°ä¼˜åŒ–æ•ˆæœ"""
        if len(self.optimization_history) < window_size:
            recent_history = self.optimization_history
        else:
            recent_history = self.optimization_history[-window_size:]
        
        if not recent_history:
            return {'error': 'No optimization history available'}
        
        # æå–æ€§èƒ½æ•°æ®
        improvement_ratios = [record['improvement_ratio'] for record in recent_history]
        success_rate = np.mean([record['optimization_success'] for record in recent_history])
        
        # è®¡ç®—å„æ€§èƒ½æŒ‡æ ‡çš„æ”¹å–„
        response_times = [record['current_performance']['response_time'] for record in recent_history]
        overshoots = [record['current_performance']['overshoot'] for record in recent_history]
        performance_scores = [record['current_performance']['performance_score'] for record in recent_history]
        
        # è®¡ç®—è¶‹åŠ¿
        if len(performance_scores) > 10:
            score_trend = np.polyfit(range(len(performance_scores)), performance_scores, 1)[0]
            trend_direction = "improving" if score_trend > 0.01 else ("declining" if score_trend < -0.01 else "stable")
        else:
            trend_direction = "insufficient_data"
        
        effectiveness = {
            'optimization_success_rate': success_rate,
            'average_improvement_ratio': np.mean(improvement_ratios),
            'performance_trend': trend_direction,
            
            'response_time_performance': {
                'average': np.mean(response_times),
                'std': np.std(response_times),
                'target_achievement_rate': np.mean([1 if rt <= self.optimization_target.target_response_time else 0 
                                                  for rt in response_times])
            },
            
            'overshoot_performance': {
                'average': np.mean(overshoots),
                'std': np.std(overshoots),
                'target_achievement_rate': np.mean([1 if os <= self.optimization_target.target_overshoot else 0 
                                                  for os in overshoots])
            },
            
            'overall_performance': {
                'average_score': np.mean(performance_scores),
                'score_improvement': score_trend if len(performance_scores) > 10 else 0.0,
                'consistency': 1.0 - np.std(performance_scores) / max(np.mean(performance_scores), 0.1)
            }
        }
        
        return effectiveness
    
    def get_optimizer_statistics(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–å™¨ç»Ÿè®¡ä¿¡æ¯"""
        effectiveness = self.evaluate_optimization_effectiveness()
        
        stats = {
            'optimizer_id': self.optimizer_id,
            'total_optimizations': self.total_optimizations,
            'successful_optimizations': self.successful_optimizations,
            'response_measurements': self.response_measurements,
            'optimization_success_rate': self.successful_optimizations / max(self.total_optimizations, 1),
            
            'optimization_targets': {
                'target_response_time': self.optimization_target.target_response_time,
                'target_overshoot': self.optimization_target.target_overshoot,
                'target_settling_time': self.optimization_target.target_settling_time,
                'target_bandwidth': self.optimization_target.target_bandwidth
            },
            
            'current_parameters': self.adaptive_controller.current_params.copy(),
            'parameter_ranges': self.adaptive_controller.param_ranges.copy(),
            
            'effectiveness_metrics': effectiveness,
            
            'data_sizes': {
                'step_response_data': len(self.step_response_data),
                'frequency_response_data': len(self.frequency_response_data),
                'optimization_history': len(self.optimization_history),
                'parameter_history': len(self.adaptive_controller.param_history)
            },
            
            'model_info': {
                'predictor_parameters': sum(p.numel() for p in self.response_predictor.parameters()),
                'model_size_mb': sum(p.numel() for p in self.response_predictor.parameters()) * 4 / (1024 * 1024)
            }
        }
        
        return stats
    
    def reset_optimizer(self):
        """é‡ç½®ä¼˜åŒ–å™¨çŠ¶æ€"""
        self.step_response_data.clear()
        self.frequency_response_data.clear()
        self.optimization_history.clear()
        self.performance_improvements.clear()
        
        self.adaptive_controller.param_history.clear()
        self.adaptive_controller.performance_history.clear()
        
        self.total_optimizations = 0
        self.successful_optimizations = 0
        self.response_measurements = 0
        
        print(f"ğŸ”„ å“åº”ä¼˜åŒ–å™¨å·²é‡ç½®: {self.optimizer_id}")
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        success_rate = self.successful_optimizations / max(self.total_optimizations, 1)
        return (f"ResponseOptimizer({self.optimizer_id}): "
                f"optimizations={self.total_optimizations}, "
                f"success_rate={success_rate:.3f}, "
                f"measurements={self.response_measurements}")
    
    def __repr__(self) -> str:
        """è¯¦ç»†å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (f"ResponseOptimizer(optimizer_id='{self.optimizer_id}', "
                f"optimizations={self.total_optimizations}, "
                f"target_response_time={self.optimization_target.target_response_time})")
