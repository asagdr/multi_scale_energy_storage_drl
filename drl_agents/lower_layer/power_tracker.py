import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from collections import deque
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from config.training_config import LowerLayerConfig
from config.model_config import ModelConfig

@dataclass
class TrackingError:
    """è·Ÿè¸ªè¯¯å·®æ•°æ®ç»“æ„"""
    instant_error: float = 0.0          # ç¬æ—¶è¯¯å·® (W)
    integral_error: float = 0.0         # ç§¯åˆ†è¯¯å·® (WÂ·s)
    derivative_error: float = 0.0       # å¾®åˆ†è¯¯å·® (W/s)
    rms_error: float = 0.0              # å‡æ–¹æ ¹è¯¯å·® (W)
    relative_error: float = 0.0         # ç›¸å¯¹è¯¯å·® (%)
    settling_time: float = 0.0          # ç¨³å®šæ—¶é—´ (s)
    overshoot: float = 0.0              # è¶…è°ƒé‡ (%)

@dataclass
class ControlPerformance:
    """æ§åˆ¶æ€§èƒ½æŒ‡æ ‡"""
    tracking_accuracy: float = 0.0      # è·Ÿè¸ªç²¾åº¦ [0,1]
    response_speed: float = 0.0         # å“åº”é€Ÿåº¦ [0,1]
    stability_margin: float = 0.0       # ç¨³å®šè£•åº¦ [0,1]
    control_effort: float = 0.0         # æ§åˆ¶åŠªåŠ› [0,1]
    robustness: float = 0.0             # é²æ£’æ€§ [0,1]

class PIDController:
    """PIDæ§åˆ¶å™¨ï¼ˆä½œä¸ºåŸºçº¿å¯¹æ¯”ï¼‰"""
    
    def __init__(self, kp: float = 1.0, ki: float = 0.1, kd: float = 0.01):
        self.kp = kp
        self.ki = ki
        self.kd = kd
        
        self.integral = 0.0
        self.previous_error = 0.0
        self.dt = 0.01  # 10ms
    
    def update(self, error: float) -> float:
        """PIDæ§åˆ¶æ›´æ–°"""
        # ç§¯åˆ†é¡¹
        self.integral += error * self.dt
        
        # å¾®åˆ†é¡¹
        derivative = (error - self.previous_error) / self.dt
        
        # PIDè¾“å‡º
        output = self.kp * error + self.ki * self.integral + self.kd * derivative
        
        self.previous_error = error
        
        return output
    
    def reset(self):
        """é‡ç½®PIDçŠ¶æ€"""
        self.integral = 0.0
        self.previous_error = 0.0

class AdaptivePIDController:
    """è‡ªé€‚åº”PIDæ§åˆ¶å™¨"""
    
    def __init__(self, initial_gains: Tuple[float, float, float] = (1.0, 0.1, 0.01)):
        self.kp, self.ki, self.kd = initial_gains
        self.initial_gains = initial_gains
        
        self.integral = 0.0
        self.previous_error = 0.0
        self.dt = 0.01
        
        # è‡ªé€‚åº”å‚æ•°
        self.error_history = deque(maxlen=100)
        self.adaptation_rate = 0.01
    
    def update(self, error: float, adaptation_enabled: bool = True) -> float:
        """è‡ªé€‚åº”PIDæ§åˆ¶æ›´æ–°"""
        # è®°å½•è¯¯å·®å†å²
        self.error_history.append(abs(error))
        
        # è‡ªé€‚åº”è°ƒæ•´å¢ç›Š
        if adaptation_enabled and len(self.error_history) >= 10:
            self._adapt_gains()
        
        # ç§¯åˆ†é¡¹
        self.integral += error * self.dt
        
        # ç§¯åˆ†é¥±å’Œé™åˆ¶
        max_integral = 1000.0
        self.integral = np.clip(self.integral, -max_integral, max_integral)
        
        # å¾®åˆ†é¡¹
        derivative = (error - self.previous_error) / self.dt
        
        # PIDè¾“å‡º
        output = self.kp * error + self.ki * self.integral + self.kd * derivative
        
        self.previous_error = error
        
        return output
    
    def _adapt_gains(self):
        """è‡ªé€‚åº”è°ƒæ•´PIDå¢ç›Š"""
        recent_errors = list(self.error_history)[-10:]
        avg_error = np.mean(recent_errors)
        error_trend = np.polyfit(range(len(recent_errors)), recent_errors, 1)[0]
        
        # åŸºäºè¯¯å·®å¤§å°è°ƒæ•´æ¯”ä¾‹å¢ç›Š
        if avg_error > 100.0:  # å¤§è¯¯å·®
            self.kp += self.adaptation_rate
        elif avg_error < 10.0:  # å°è¯¯å·®
            self.kp -= self.adaptation_rate * 0.5
        
        # åŸºäºè¯¯å·®è¶‹åŠ¿è°ƒæ•´ç§¯åˆ†å¢ç›Š
        if error_trend > 0:  # è¯¯å·®å¢åŠ 
            self.ki += self.adaptation_rate * 0.1
        else:  # è¯¯å·®å‡å°‘
            self.ki -= self.adaptation_rate * 0.05
        
        # åŸºäºè¯¯å·®å˜åŒ–è°ƒæ•´å¾®åˆ†å¢ç›Š
        error_variance = np.var(recent_errors)
        if error_variance > 50.0:  # è¯¯å·®å˜åŒ–å¤§
            self.kd += self.adaptation_rate * 0.01
        
        # é™åˆ¶å¢ç›ŠèŒƒå›´
        self.kp = np.clip(self.kp, 0.1, 10.0)
        self.ki = np.clip(self.ki, 0.01, 1.0)
        self.kd = np.clip(self.kd, 0.001, 0.1)
    
    def reset(self):
        """é‡ç½®æ§åˆ¶å™¨çŠ¶æ€"""
        self.integral = 0.0
        self.previous_error = 0.0
        self.error_history.clear()
        self.kp, self.ki, self.kd = self.initial_gains

class NeuralPowerTracker(nn.Module):
    """ç¥ç»ç½‘ç»œåŠŸç‡è·Ÿè¸ªå™¨"""
    
    def __init__(self, 
                 input_dim: int = 10, 
                 hidden_dim: int = 128,
                 output_dim: int = 1):
        super(NeuralPowerTracker, self).__init__()
        
        # ç‰¹å¾æå–ç½‘ç»œ
        self.feature_extractor = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.LayerNorm(hidden_dim),
            nn.Dropout(0.1),
            
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.LayerNorm(hidden_dim // 2),
            nn.Dropout(0.1)
        )
        
        # æ§åˆ¶ä¿¡å·ç”Ÿæˆ
        self.control_head = nn.Sequential(
            nn.Linear(hidden_dim // 2, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, output_dim),
            nn.Tanh()
        )
        
        # è¯¯å·®é¢„æµ‹å¤´
        self.error_predictor = nn.Sequential(
            nn.Linear(hidden_dim // 2, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1)
        )
        
        # ç¨³å®šæ—¶é—´é¢„æµ‹å¤´
        self.settling_time_predictor = nn.Sequential(
            nn.Linear(hidden_dim // 2, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Sigmoid()
        )
    
    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        """å‰å‘ä¼ æ’­"""
        features = self.feature_extractor(x)
        
        control_signal = self.control_head(features)
        predicted_error = self.error_predictor(features)
        settling_time = self.settling_time_predictor(features) * 2.0  # 0-2s
        
        return {
            'control_signal': control_signal,
            'predicted_error': predicted_error,
            'settling_time': settling_time,
            'features': features
        }

class PowerTracker(nn.Module):
    """
    åŠŸç‡è·Ÿè¸ªæ§åˆ¶å™¨
    å®ç°é«˜ç²¾åº¦ã€å¿«å“åº”çš„åŠŸç‡è·Ÿè¸ªæ§åˆ¶
    """
    
    def __init__(self,
                 config: LowerLayerConfig,
                 model_config: ModelConfig,
                 tracker_id: str = "PowerTracker_001"):
        """
        åˆå§‹åŒ–åŠŸç‡è·Ÿè¸ªå™¨
        
        Args:
            config: ä¸‹å±‚é…ç½®
            model_config: æ¨¡å‹é…ç½®
            tracker_id: è·Ÿè¸ªå™¨ID
        """
        super(PowerTracker, self).__init__()
        
        self.config = config
        self.model_config = model_config
        self.tracker_id = tracker_id
        
        # === æ§åˆ¶å™¨å‚æ•° ===
        self.dt = 0.01  # 10msæ—¶é—´æ­¥
        self.response_time_target = config.response_time
        
        # === ç¥ç»ç½‘ç»œè·Ÿè¸ªå™¨ ===
        self.neural_tracker = NeuralPowerTracker(
            input_dim=15,  # [power_error, error_derivative, error_integral, reference, current_power, ...]
            hidden_dim=128,
            output_dim=3   # [control_signal, feed_forward, compensation]
        )
        
        # === ä¼ ç»Ÿæ§åˆ¶å™¨ï¼ˆç”¨äºå¯¹æ¯”å’Œå¤‡ä»½ï¼‰ ===
        self.pid_controller = AdaptivePIDController((2.0, 0.5, 0.1))
        self.feedforward_gain = 0.8
        
        # === è·Ÿè¸ªå†å² ===
        self.tracking_history: List[Dict] = []
        self.error_history = deque(maxlen=1000)
        
        # === æ€§èƒ½ç»Ÿè®¡ ===
        self.performance_metrics = ControlPerformance()
        self.total_tracking_steps = 0
        
        # === è‡ªé€‚åº”å‚æ•° ===
        self.adaptation_enabled = True
        self.control_mode = "neural"  # "neural", "pid", "hybrid"
        
        print(f"âœ… åŠŸç‡è·Ÿè¸ªå™¨åˆå§‹åŒ–å®Œæˆ: {tracker_id}")
        print(f"   ç›®æ ‡å“åº”æ—¶é—´: {self.response_time_target}s")
        print(f"   æ§åˆ¶æ¨¡å¼: {self.control_mode}")
    
    def track_power(self, 
                   power_reference: float,
                   current_power: float,
                   system_state: Dict[str, Any],
                   constraints: Optional[Dict[str, float]] = None) -> Dict[str, Any]:
        """
        åŠŸç‡è·Ÿè¸ªæ§åˆ¶
        
        Args:
            power_reference: åŠŸç‡å‚è€ƒå€¼ (W)
            current_power: å½“å‰åŠŸç‡ (W)
            system_state: ç³»ç»ŸçŠ¶æ€
            constraints: æ§åˆ¶çº¦æŸ
            
        Returns:
            æ§åˆ¶ç»“æœ
        """
        # === 1. è®¡ç®—è·Ÿè¸ªè¯¯å·® ===
        tracking_error = self._calculate_tracking_error(power_reference, current_power)
        
        # === 2. å‡†å¤‡æ§åˆ¶è¾“å…¥ ===
        control_input = self._prepare_control_input(
            tracking_error, power_reference, current_power, system_state
        )
        
        # === 3. ç”Ÿæˆæ§åˆ¶ä¿¡å· ===
        if self.control_mode == "neural":
            control_result = self._neural_control(control_input, tracking_error)
        elif self.control_mode == "pid":
            control_result = self._pid_control(tracking_error)
        else:  # hybrid
            control_result = self._hybrid_control(control_input, tracking_error)
        
        # === 4. åº”ç”¨çº¦æŸ ===
        if constraints:
            control_result = self._apply_constraints(control_result, constraints)
        
        # === 5. è®°å½•è·Ÿè¸ªå†å² ===
        self._record_tracking_step(
            power_reference, current_power, tracking_error, control_result, system_state
        )
        
        # === 6. æ›´æ–°æ€§èƒ½æŒ‡æ ‡ ===
        self._update_performance_metrics(tracking_error, control_result)
        
        self.total_tracking_steps += 1
        
        return control_result
    
    def _calculate_tracking_error(self, reference: float, current: float) -> TrackingError:
        """è®¡ç®—è·Ÿè¸ªè¯¯å·®"""
        instant_error = reference - current
        
        # è®¡ç®—ç§¯åˆ†è¯¯å·®
        if len(self.error_history) > 0:
            integral_error = sum(self.error_history) * self.dt + instant_error * self.dt
        else:
            integral_error = instant_error * self.dt
        
        # è®¡ç®—å¾®åˆ†è¯¯å·®
        if len(self.error_history) > 0:
            derivative_error = (instant_error - self.error_history[-1]) / self.dt
        else:
            derivative_error = 0.0
        
        # è®¡ç®—RMSè¯¯å·®
        recent_errors = list(self.error_history)[-50:] + [instant_error]
        rms_error = np.sqrt(np.mean([e**2 for e in recent_errors]))
        
        # è®¡ç®—ç›¸å¯¹è¯¯å·®
        relative_error = abs(instant_error) / max(abs(reference), 1.0) * 100.0
        
        # ä¼°ç®—ç¨³å®šæ—¶é—´å’Œè¶…è°ƒé‡
        settling_time, overshoot = self._estimate_settling_metrics(recent_errors)
        
        error = TrackingError(
            instant_error=instant_error,
            integral_error=integral_error,
            derivative_error=derivative_error,
            rms_error=rms_error,
            relative_error=relative_error,
            settling_time=settling_time,
            overshoot=overshoot
        )
        
        # æ›´æ–°è¯¯å·®å†å²
        self.error_history.append(instant_error)
        
        return error
    
    def _estimate_settling_metrics(self, errors: List[float]) -> Tuple[float, float]:
        """ä¼°ç®—ç¨³å®šæ—¶é—´å’Œè¶…è°ƒé‡"""
        if len(errors) < 10:
            return 0.0, 0.0
        
        # ç¨³å®šæ—¶é—´ï¼šè¯¯å·®è¿›å…¥Â±2%èŒƒå›´çš„æ—¶é—´
        settling_threshold = abs(errors[0]) * 0.02 if errors[0] != 0 else 1.0
        settling_time = 0.0
        
        for i, error in enumerate(reversed(errors)):
            if abs(error) > settling_threshold:
                settling_time = i * self.dt
                break
        
        # è¶…è°ƒé‡ï¼šæœ€å¤§åå·®ç›¸å¯¹äºç¨³æ€å€¼çš„ç™¾åˆ†æ¯”
        max_error = max(abs(e) for e in errors)
        steady_state_error = abs(np.mean(errors[-5:]))
        overshoot = ((max_error - steady_state_error) / max(steady_state_error, 1.0)) * 100.0
        
        return settling_time, overshoot
    
    def _prepare_control_input(self, 
                             error: TrackingError,
                             reference: float,
                             current: float,
                             system_state: Dict[str, Any]) -> torch.Tensor:
        """å‡†å¤‡ç¥ç»ç½‘ç»œæ§åˆ¶è¾“å…¥"""
        # å½’ä¸€åŒ–è¾“å…¥ç‰¹å¾
        max_power = 100000.0  # 100kWå½’ä¸€åŒ–åŸºå‡†
        
        input_features = [
            error.instant_error / max_power,
            error.derivative_error / (max_power / self.dt),
            error.integral_error / (max_power * self.dt),
            reference / max_power,
            current / max_power,
            error.relative_error / 100.0,
            error.rms_error / max_power,
            
            # ç³»ç»ŸçŠ¶æ€ç‰¹å¾
            system_state.get('soc', 50.0) / 100.0,
            system_state.get('temperature', 25.0) / 60.0,
            system_state.get('voltage', 3.4) / 4.2,
            system_state.get('soh', 100.0) / 100.0,
            
            # æ—¶é—´ç‰¹å¾
            (self.total_tracking_steps % 100) / 100.0,  # å‘¨æœŸæ€§ç‰¹å¾
            min(self.total_tracking_steps / 10000.0, 1.0),  # ç»éªŒç‰¹å¾
            
            # çº¦æŸç‰¹å¾
            system_state.get('constraint_severity', 0.0),
            system_state.get('thermal_constraint_active', 0.0)
        ]
        
        return torch.tensor(input_features, dtype=torch.float32).unsqueeze(0)
    
    def _neural_control(self, 
                       control_input: torch.Tensor, 
                       error: TrackingError) -> Dict[str, Any]:
        """ç¥ç»ç½‘ç»œæ§åˆ¶"""
        self.neural_tracker.eval()
        
        with torch.no_grad():
            neural_output = self.neural_tracker(control_input)
        
        # è§£æç¥ç»ç½‘ç»œè¾“å‡º
        control_signals = neural_output['control_signal'].squeeze(0)
        
        primary_control = control_signals[0].item() * 10000.0  # W
        feedforward_control = control_signals[1].item() * 5000.0  # W
        compensation_control = control_signals[2].item() * 2000.0  # W
        
        # ç»„åˆæ§åˆ¶ä¿¡å·
        total_control = primary_control + feedforward_control + compensation_control
        
        # é¢„æµ‹æ€§èƒ½
        predicted_error = neural_output['predicted_error'].item()
        predicted_settling_time = neural_output['settling_time'].item()
        
        return {
            'control_signal': total_control,
            'primary_control': primary_control,
            'feedforward_control': feedforward_control,
            'compensation_control': compensation_control,
            'predicted_error': predicted_error,
            'predicted_settling_time': predicted_settling_time,
            'control_confidence': min(1.0, 1.0 / (abs(predicted_error) + 0.1)),
            'control_type': 'neural'
        }
    
    def _pid_control(self, error: TrackingError) -> Dict[str, Any]:
        """PIDæ§åˆ¶"""
        pid_output = self.pid_controller.update(error.instant_error)
        
        # å‰é¦ˆæ§åˆ¶
        feedforward = 0.0
        if len(self.tracking_history) > 0:
            recent_reference = self.tracking_history[-1]['power_reference']
            feedforward = recent_reference * self.feedforward_gain
        
        total_control = pid_output + feedforward
        
        return {
            'control_signal': total_control,
            'primary_control': pid_output,
            'feedforward_control': feedforward,
            'compensation_control': 0.0,
            'predicted_error': abs(error.instant_error) * 0.9,  # ç®€å•é¢„æµ‹
            'predicted_settling_time': self.response_time_target,
            'control_confidence': min(1.0, 100.0 / (abs(error.instant_error) + 1.0)),
            'control_type': 'pid',
            'pid_gains': [self.pid_controller.kp, self.pid_controller.ki, self.pid_controller.kd]
        }
    
    def _hybrid_control(self, 
                       control_input: torch.Tensor, 
                       error: TrackingError) -> Dict[str, Any]:
        """æ··åˆæ§åˆ¶ï¼ˆç¥ç»ç½‘ç»œ+PIDï¼‰"""
        # ç¥ç»ç½‘ç»œæ§åˆ¶
        neural_result = self._neural_control(control_input, error)
        
        # PIDæ§åˆ¶
        pid_result = self._pid_control(error)
        
        # åŠ¨æ€æƒé‡åˆ†é…
        error_magnitude = abs(error.instant_error)
        if error_magnitude > 1000.0:  # å¤§è¯¯å·®æ—¶åå‘PID
            neural_weight = 0.3
            pid_weight = 0.7
        elif error_magnitude < 100.0:  # å°è¯¯å·®æ—¶åå‘ç¥ç»ç½‘ç»œ
            neural_weight = 0.8
            pid_weight = 0.2
        else:  # ä¸­ç­‰è¯¯å·®æ—¶å¹³è¡¡
            neural_weight = 0.6
            pid_weight = 0.4
        
        # åŠ æƒç»„åˆ
        combined_control = (neural_weight * neural_result['control_signal'] + 
                          pid_weight * pid_result['control_signal'])
        
        return {
            'control_signal': combined_control,
            'primary_control': combined_control,
            'feedforward_control': neural_result['feedforward_control'],
            'compensation_control': neural_result['compensation_control'],
            'predicted_error': (neural_weight * neural_result['predicted_error'] + 
                              pid_weight * pid_result['predicted_error']),
            'predicted_settling_time': min(neural_result['predicted_settling_time'],
                                         pid_result['predicted_settling_time']),
            'control_confidence': max(neural_result['control_confidence'],
                                    pid_result['control_confidence']),
            'control_type': 'hybrid',
            'neural_weight': neural_weight,
            'pid_weight': pid_weight
        }
    
    def _apply_constraints(self, 
                          control_result: Dict[str, Any], 
                          constraints: Dict[str, float]) -> Dict[str, Any]:
        """åº”ç”¨æ§åˆ¶çº¦æŸ"""
        control_signal = control_result['control_signal']
        
        # åŠŸç‡å˜åŒ–ç‡çº¦æŸ
        max_power_change_rate = constraints.get('max_power_change_rate', 10000.0)  # W/s
        max_change_per_step = max_power_change_rate * self.dt
        
        if len(self.tracking_history) > 0:
            last_control = self.tracking_history[-1]['control_result']['control_signal']
            control_change = control_signal - last_control
            
            if abs(control_change) > max_change_per_step:
                control_signal = last_control + np.sign(control_change) * max_change_per_step
        
        # åŠŸç‡å¹…å€¼çº¦æŸ
        max_power = constraints.get('max_power', 50000.0)  # W
        control_signal = np.clip(control_signal, -max_power, max_power)
        
        # æ›´æ–°æ§åˆ¶ç»“æœ
        control_result = control_result.copy()
        control_result['control_signal'] = control_signal
        control_result['constraint_applied'] = True
        
        return control_result
    
    def _record_tracking_step(self, 
                             reference: float,
                             current: float,
                             error: TrackingError,
                             control_result: Dict[str, Any],
                             system_state: Dict[str, Any]):
        """è®°å½•è·Ÿè¸ªæ­¥éª¤"""
        record = {
            'step': self.total_tracking_steps,
            'timestamp': self.total_tracking_steps * self.dt,
            'power_reference': reference,
            'current_power': current,
            'tracking_error': error,
            'control_result': control_result,
            'system_state': system_state.copy()
        }
        
        self.tracking_history.append(record)
        
        # ç»´æŠ¤å†å²é•¿åº¦
        if len(self.tracking_history) > 10000:
            self.tracking_history.pop(0)
    
    def _update_performance_metrics(self, 
                                   error: TrackingError, 
                                   control_result: Dict[str, Any]):
        """æ›´æ–°æ€§èƒ½æŒ‡æ ‡"""
        # è·Ÿè¸ªç²¾åº¦
        self.performance_metrics.tracking_accuracy = 1.0 - min(1.0, error.rms_error / 1000.0)
        
        # å“åº”é€Ÿåº¦
        self.performance_metrics.response_speed = max(0.0, 1.0 - error.settling_time / (self.response_time_target * 2))
        
        # ç¨³å®šè£•åº¦
        self.performance_metrics.stability_margin = max(0.0, 1.0 - error.overshoot / 50.0)
        
        # æ§åˆ¶åŠªåŠ›
        control_effort = abs(control_result['control_signal']) / 50000.0  # å½’ä¸€åŒ–åˆ°50kW
        self.performance_metrics.control_effort = min(1.0, control_effort)
        
        # é²æ£’æ€§ï¼ˆåŸºäºæœ€è¿‘çš„æ€§èƒ½ä¸€è‡´æ€§ï¼‰
        if len(self.tracking_history) >= 100:
            recent_errors = [record['tracking_error'].rms_error for record in self.tracking_history[-100:]]
            error_consistency = 1.0 - np.std(recent_errors) / max(np.mean(recent_errors), 1.0)
            self.performance_metrics.robustness = max(0.0, error_consistency)
    
    def evaluate_tracking_performance(self, window_size: int = 1000) -> Dict[str, float]:
        """è¯„ä¼°è·Ÿè¸ªæ€§èƒ½"""
        if len(self.tracking_history) < window_size:
            recent_history = self.tracking_history
        else:
            recent_history = self.tracking_history[-window_size:]
        
        if not recent_history:
            return {'error': 'No tracking history available'}
        
        # æå–æ€§èƒ½æ•°æ®
        instant_errors = [record['tracking_error'].instant_error for record in recent_history]
        rms_errors = [record['tracking_error'].rms_error for record in recent_history]
        settling_times = [record['tracking_error'].settling_time for record in recent_history]
        overshoots = [record['tracking_error'].overshoot for record in recent_history]
        relative_errors = [record['tracking_error'].relative_error for record in recent_history]
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        performance = {
            'avg_instant_error': np.mean(np.abs(instant_errors)),
            'max_instant_error': max(np.abs(instant_errors)),
            'avg_rms_error': np.mean(rms_errors),
            'avg_settling_time': np.mean(settling_times),
            'max_settling_time': max(settling_times),
            'avg_overshoot': np.mean(overshoots),
            'max_overshoot': max(overshoots),
            'avg_relative_error': np.mean(relative_errors),
            
            # æ€§èƒ½æŒ‡æ ‡
            'tracking_accuracy': self.performance_metrics.tracking_accuracy,
            'response_speed': self.performance_metrics.response_speed,
            'stability_margin': self.performance_metrics.stability_margin,
            'control_effort': self.performance_metrics.control_effort,
            'robustness': self.performance_metrics.robustness,
            
            # å“åº”æ—¶é—´æ€§èƒ½
            'response_time_compliance': np.mean([1.0 if t <= self.response_time_target else 0.0 
                                               for t in settling_times]),
            
            # è¯¯å·®åˆ†å¸ƒ
            'error_percentiles': {
                '50th': np.percentile(np.abs(instant_errors), 50),
                '90th': np.percentile(np.abs(instant_errors), 90),
                '95th': np.percentile(np.abs(instant_errors), 95),
                '99th': np.percentile(np.abs(instant_errors), 99)
            }
        }
        
        return performance
    
    def adapt_control_parameters(self, performance_feedback: Dict[str, float]) -> bool:
        """æ ¹æ®æ€§èƒ½åé¦ˆè‡ªé€‚åº”è°ƒæ•´æ§åˆ¶å‚æ•°"""
        if not self.adaptation_enabled:
            return False
        
        try:
            # è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡
            tracking_accuracy = performance_feedback.get('tracking_accuracy', 0.8)
            response_speed = performance_feedback.get('response_speed', 0.8)
            stability_margin = performance_feedback.get('stability_margin', 0.8)
            
            # æ ¹æ®æ€§èƒ½è°ƒæ•´æ§åˆ¶æ¨¡å¼
            if tracking_accuracy < 0.7 and response_speed < 0.7:
                # æ€§èƒ½ä¸ä½³ï¼Œåˆ‡æ¢åˆ°æ··åˆæ¨¡å¼
                self.control_mode = "hybrid"
                print(f"ğŸ”„ åˆ‡æ¢åˆ°æ··åˆæ§åˆ¶æ¨¡å¼")
            elif tracking_accuracy > 0.9 and response_speed > 0.9:
                # æ€§èƒ½ä¼˜ç§€ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡å¼
                self.control_mode = "neural"
            elif stability_margin < 0.6:
                # ç¨³å®šæ€§ä¸ä½³ï¼Œä½¿ç”¨PIDæ¨¡å¼
                self.control_mode = "pid"
                print(f"ğŸ”„ åˆ‡æ¢åˆ°PIDæ§åˆ¶æ¨¡å¼")
            
            # è°ƒæ•´PIDå‚æ•°
            avg_error = performance_feedback.get('avg_instant_error', 0.0)
            if avg_error > 500.0:  # å¤§è¯¯å·®
                self.pid_controller.kp = min(5.0, self.pid_controller.kp * 1.1)
            elif avg_error < 50.0:  # å°è¯¯å·®
                self.pid_controller.kp = max(0.5, self.pid_controller.kp * 0.95)
            
            # è°ƒæ•´å‰é¦ˆå¢ç›Š
            response_time_compliance = performance_feedback.get('response_time_compliance', 1.0)
            if response_time_compliance < 0.8:
                self.feedforward_gain = min(1.0, self.feedforward_gain * 1.05)
            
            return True
            
        except Exception as e:
            print(f"âŒ æ§åˆ¶å‚æ•°è‡ªé€‚åº”å¤±è´¥: {str(e)}")
            return False
    
    def reset_tracker(self):
        """é‡ç½®è·Ÿè¸ªå™¨çŠ¶æ€"""
        self.error_history.clear()
        self.tracking_history.clear()
        self.pid_controller.reset()
        self.total_tracking_steps = 0
        self.performance_metrics = ControlPerformance()
        
        print(f"ğŸ”„ åŠŸç‡è·Ÿè¸ªå™¨å·²é‡ç½®: {self.tracker_id}")
    
    def get_tracker_statistics(self) -> Dict[str, Any]:
        """è·å–è·Ÿè¸ªå™¨ç»Ÿè®¡ä¿¡æ¯"""
        performance = self.evaluate_tracking_performance()
        
        stats = {
            'tracker_id': self.tracker_id,
            'total_tracking_steps': self.total_tracking_steps,
            'control_mode': self.control_mode,
            'adaptation_enabled': self.adaptation_enabled,
            
            'performance_metrics': performance,
            
            'current_parameters': {
                'pid_gains': [self.pid_controller.kp, self.pid_controller.ki, self.pid_controller.kd],
                'feedforward_gain': self.feedforward_gain,
                'response_time_target': self.response_time_target
            },
            
            'model_info': {
                'neural_tracker_parameters': sum(p.numel() for p in self.neural_tracker.parameters()),
                'model_size_mb': sum(p.numel() for p in self.neural_tracker.parameters()) * 4 / (1024 * 1024)
            },
            
            'tracking_history_size': len(self.tracking_history),
            'error_history_size': len(self.error_history)
        }
        
        return stats
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (f"PowerTracker({self.tracker_id}): "
                f"mode={self.control_mode}, steps={self.total_tracking_steps}, "
                f"accuracy={self.performance_metrics.tracking_accuracy:.3f}")
    
    def __repr__(self) -> str:
        """è¯¦ç»†å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (f"PowerTracker(tracker_id='{self.tracker_id}', "
                f"control_mode='{self.control_mode}', "
                f"tracking_steps={self.total_tracking_steps})")
