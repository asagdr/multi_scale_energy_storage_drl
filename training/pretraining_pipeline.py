import torch
import torch.nn as nn
import numpy as np
import time
import os
import logging
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
import json
from enum import Enum
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from config.training_config import TrainingConfig, UpperLayerConfig, LowerLayerConfig
from config.model_config import ModelConfig
from .upper_trainer import UpperLayerTrainer
from .lower_trainer import LowerLayerTrainer

class PretrainingStage(Enum):
    """é¢„è®­ç»ƒé˜¶æ®µæšä¸¾"""
    INITIALIZATION = "initialization"
    UPPER_PRETRAINING = "upper_pretraining"
    LOWER_PRETRAINING = "lower_pretraining"
    KNOWLEDGE_TRANSFER = "knowledge_transfer"
    JOINT_FINETUNING = "joint_finetuning"
    COMPLETED = "completed"

@dataclass
class PretrainingMetrics:
    """é¢„è®­ç»ƒæŒ‡æ ‡"""
    stage: PretrainingStage
    stage_episode: int = 0
    total_episode: int = 0
    
    # é˜¶æ®µæ€§èƒ½
    stage_performance: float = 0.0
    performance_improvement: float = 0.0
    convergence_score: float = 0.0
    
    # çŸ¥è¯†è¿ç§»
    knowledge_transfer_score: float = 0.0
    transfer_efficiency: float = 0.0
    
    # æ—¶é—´æŒ‡æ ‡
    stage_time: float = 0.0
    cumulative_time: float = 0.0
    
    # é˜¶æ®µç‰¹å®šæŒ‡æ ‡
    stage_specific_metrics: Dict[str, float] = field(default_factory=dict)

class CurriculumLearning:
    """è¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨"""
    
    def __init__(self, curriculum_id: str = "Curriculum_001"):
        self.curriculum_id = curriculum_id
        
        # è¯¾ç¨‹é…ç½®
        self.curriculum_config = {
            'difficulty_progression': 'linear',  # 'linear', 'exponential', 'adaptive'
            'initial_difficulty': 0.3,           # åˆå§‹éš¾åº¦
            'final_difficulty': 1.0,             # æœ€ç»ˆéš¾åº¦
            'adaptation_rate': 0.1,              # è‡ªé€‚åº”ç‡
            'performance_threshold': 0.7         # æ€§èƒ½é˜ˆå€¼
        }
        
        # å½“å‰çŠ¶æ€
        self.current_difficulty = self.curriculum_config['initial_difficulty']
        self.performance_history = []
        
    def get_current_difficulty(self, episode: int, total_episodes: int, performance: float = None) -> float:
        """è·å–å½“å‰éš¾åº¦"""
        if self.curriculum_config['difficulty_progression'] == 'linear':
            # çº¿æ€§å¢é•¿
            progress = episode / total_episodes
            self.current_difficulty = (
                self.curriculum_config['initial_difficulty'] + 
                progress * (self.curriculum_config['final_difficulty'] - self.curriculum_config['initial_difficulty'])
            )
            
        elif self.curriculum_config['difficulty_progression'] == 'exponential':
            # æŒ‡æ•°å¢é•¿
            progress = episode / total_episodes
            self.current_difficulty = (
                self.curriculum_config['initial_difficulty'] * 
                (self.curriculum_config['final_difficulty'] / self.curriculum_config['initial_difficulty']) ** progress
            )
            
        elif self.curriculum_config['difficulty_progression'] == 'adaptive':
            # è‡ªé€‚åº”è°ƒæ•´
            if performance is not None:
                self.performance_history.append(performance)
                
                if len(self.performance_history) >= 10:
                    avg_performance = np.mean(self.performance_history[-10:])
                    
                    if avg_performance > self.curriculum_config['performance_threshold']:
                        # æ€§èƒ½è‰¯å¥½ï¼Œå¢åŠ éš¾åº¦
                        self.current_difficulty = min(
                            self.curriculum_config['final_difficulty'],
                            self.current_difficulty + self.curriculum_config['adaptation_rate']
                        )
                    elif avg_performance < self.curriculum_config['performance_threshold'] * 0.8:
                        # æ€§èƒ½ä¸ä½³ï¼Œé™ä½éš¾åº¦
                        self.current_difficulty = max(
                            self.curriculum_config['initial_difficulty'],
                            self.current_difficulty - self.curriculum_config['adaptation_rate']
                        )
        
        return self.current_difficulty
    
    def generate_curriculum_parameters(self, difficulty: float) -> Dict[str, Any]:
        """ç”Ÿæˆè¯¾ç¨‹å‚æ•°"""
        return {
            'scenario_complexity': difficulty,
            'noise_level': 0.1 + difficulty * 0.2,
            'constraint_strictness': 0.5 + difficulty * 0.5,
            'disturbance_magnitude': difficulty * 0.3,
            'multi_objective_weights': self._generate_weights(difficulty)
        }
    
    def _generate_weights(self, difficulty: float) -> List[float]:
        """ç”Ÿæˆå¤šç›®æ ‡æƒé‡"""
        if difficulty < 0.5:
            # ç®€å•é˜¶æ®µï¼šä¸“æ³¨å•ä¸€ç›®æ ‡
            return [0.7, 0.1, 0.1, 0.1]
        elif difficulty < 0.8:
            # ä¸­ç­‰é˜¶æ®µï¼šåŒç›®æ ‡
            return [0.4, 0.4, 0.1, 0.1]
        else:
            # å›°éš¾é˜¶æ®µï¼šå¤šç›®æ ‡å‡è¡¡
            return [0.25, 0.25, 0.25, 0.25]

class KnowledgeTransfer:
    """çŸ¥è¯†è¿ç§»ç®¡ç†å™¨"""
    
    def __init__(self, transfer_id: str = "KnowledgeTransfer_001"):
        self.transfer_id = transfer_id
        
        # è¿ç§»ç­–ç•¥
        self.transfer_strategies = {
            'feature_extraction': True,    # ç‰¹å¾æå–
            'fine_tuning': True,          # å¾®è°ƒ
            'progressive_unfreezing': True, # æ¸è¿›è§£å†»
            'distillation': False         # çŸ¥è¯†è’¸é¦
        }
        
        # è¿ç§»å†å²
        self.transfer_history = []
        
    def transfer_upper_to_lower(self,
                               upper_agent: nn.Module,
                               lower_agent: nn.Module) -> Dict[str, float]:
        """ä¸Šå±‚åˆ°ä¸‹å±‚çš„çŸ¥è¯†è¿ç§»"""
        transfer_start_time = time.time()
        
        # ç‰¹å¾æå–å™¨è¿ç§»
        if self.transfer_strategies['feature_extraction']:
            transfer_score = self._transfer_feature_extractor(upper_agent, lower_agent)
        else:
            transfer_score = 0.0
        
        # ç­–ç•¥ç½‘ç»œå¾®è°ƒ
        if self.transfer_strategies['fine_tuning']:
            fine_tuning_score = self._fine_tune_policy(upper_agent, lower_agent)
            transfer_score = (transfer_score + fine_tuning_score) / 2
        
        transfer_time = time.time() - transfer_start_time
        
        # è®°å½•è¿ç§»å†å²
        transfer_record = {
            'direction': 'upper_to_lower',
            'transfer_score': transfer_score,
            'transfer_time': transfer_time,
            'strategies_used': [k for k, v in self.transfer_strategies.items() if v]
        }
        self.transfer_history.append(transfer_record)
        
        return {
            'transfer_score': transfer_score,
            'transfer_time': transfer_time,
            'transfer_success': transfer_score > 0.5
        }
    
    def transfer_lower_to_upper(self,
                               lower_agent: nn.Module,
                               upper_agent: nn.Module) -> Dict[str, float]:
        """ä¸‹å±‚åˆ°ä¸Šå±‚çš„çŸ¥è¯†è¿ç§»"""
        transfer_start_time = time.time()
        
        # æ§åˆ¶ç­–ç•¥è¿ç§»
        control_transfer_score = self._transfer_control_strategy(lower_agent, upper_agent)
        
        # çº¦æŸå¤„ç†è¿ç§»
        constraint_transfer_score = self._transfer_constraint_handling(lower_agent, upper_agent)
        
        # ç»¼åˆè¿ç§»å¾—åˆ†
        transfer_score = (control_transfer_score + constraint_transfer_score) / 2
        
        transfer_time = time.time() - transfer_start_time
        
        # è®°å½•è¿ç§»å†å²
        transfer_record = {
            'direction': 'lower_to_upper',
            'transfer_score': transfer_score,
            'transfer_time': transfer_time,
            'control_transfer': control_transfer_score,
            'constraint_transfer': constraint_transfer_score
        }
        self.transfer_history.append(transfer_record)
        
        return {
            'transfer_score': transfer_score,
            'transfer_time': transfer_time,
            'transfer_success': transfer_score > 0.5
        }
    
    def _transfer_feature_extractor(self, source_agent: nn.Module, target_agent: nn.Module) -> float:
        """è¿ç§»ç‰¹å¾æå–å™¨"""
        try:
            # å‡è®¾ä¸¤ä¸ªæ™ºèƒ½ä½“éƒ½æœ‰feature_extractorå±æ€§
            if hasattr(source_agent, 'transformer_encoder') and hasattr(target_agent, 'neural_tracker'):
                source_features = source_agent.transformer_encoder.state_dict()
                target_features = target_agent.neural_tracker.state_dict()
                
                # è¿ç§»å…¼å®¹çš„å±‚
                transferred_layers = 0
                total_layers = 0
                
                for source_key, source_param in source_features.items():
                    total_layers += 1
                    # å¯»æ‰¾å…¼å®¹çš„ç›®æ ‡å±‚
                    for target_key, target_param in target_features.items():
                        if source_param.shape == target_param.shape:
                            target_param.data.copy_(source_param.data)
                            transferred_layers += 1
                            break
                
                return transferred_layers / max(total_layers, 1)
            
            return 0.3  # é»˜è®¤è¿ç§»å¾—åˆ†
            
        except Exception as e:
            print(f"ç‰¹å¾æå–å™¨è¿ç§»å¤±è´¥: {str(e)}")
            return 0.0
    
    def _fine_tune_policy(self, source_agent: nn.Module, target_agent: nn.Module) -> float:
        """å¾®è°ƒç­–ç•¥ç½‘ç»œ"""
        try:
            # ç­–ç•¥ç½‘ç»œå‚æ•°å¾®è°ƒ
            if hasattr(source_agent, 'actor') and hasattr(target_agent, 'actor'):
                source_policy = source_agent.actor.state_dict()
                target_policy = target_agent.actor.state_dict()
                
                # è®¡ç®—å‚æ•°ç›¸ä¼¼åº¦
                similarity_scores = []
                
                for source_key, source_param in source_policy.items():
                    for target_key, target_param in target_policy.items():
                        if source_param.shape == target_param.shape:
                            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                            source_flat = source_param.flatten()
                            target_flat = target_param.flatten()
                            
                            similarity = torch.cosine_similarity(
                                source_flat.unsqueeze(0), 
                                target_flat.unsqueeze(0)
                            ).item()
                            similarity_scores.append(abs(similarity))
                            break
                
                return np.mean(similarity_scores) if similarity_scores else 0.2
            
            return 0.2  # é»˜è®¤å¾®è°ƒå¾—åˆ†
            
        except Exception as e:
            print(f"ç­–ç•¥å¾®è°ƒå¤±è´¥: {str(e)}")
            return 0.0
    
    def _transfer_control_strategy(self, source_agent: nn.Module, target_agent: nn.Module) -> float:
        """è¿ç§»æ§åˆ¶ç­–ç•¥"""
        # ç®€åŒ–çš„æ§åˆ¶ç­–ç•¥è¿ç§»
        return 0.6  # æ¨¡æ‹Ÿè¿ç§»å¾—åˆ†
    
    def _transfer_constraint_handling(self, source_agent: nn.Module, target_agent: nn.Module) -> float:
        """è¿ç§»çº¦æŸå¤„ç†"""
        # ç®€åŒ–çš„çº¦æŸå¤„ç†è¿ç§»
        return 0.7  # æ¨¡æ‹Ÿè¿ç§»å¾—åˆ†

class PretrainingPipeline:
    """
    é¢„è®­ç»ƒæµæ°´çº¿
    å®ç°åˆ†å±‚DRLçš„æ¸è¿›å¼é¢„è®­ç»ƒç­–ç•¥
    """
    
    def __init__(self,
                 config: TrainingConfig,
                 model_config: ModelConfig,
                 pipeline_id: str = "PretrainingPipeline_001"):
        """
        åˆå§‹åŒ–é¢„è®­ç»ƒæµæ°´çº¿
        
        Args:
            config: è®­ç»ƒé…ç½®
            model_config: æ¨¡å‹é…ç½®
            pipeline_id: æµæ°´çº¿ID
        """
        self.config = config
        self.model_config = model_config
        self.pipeline_id = pipeline_id
        
        # === åˆå§‹åŒ–å­è®­ç»ƒå™¨ ===
        self.upper_trainer = UpperLayerTrainer(
            config=config.upper_config,
            model_config=model_config,
            trainer_id=f"PretrainUpper_{pipeline_id}"
        )
        
        self.lower_trainer = LowerLayerTrainer(
            config=config.lower_config,
            model_config=model_config,
            trainer_id=f"PretrainLower_{pipeline_id}"
        )
        
        # === åˆå§‹åŒ–ç®¡ç†å™¨ ===
        self.curriculum_learning = CurriculumLearning(f"Curriculum_{pipeline_id}")
        self.knowledge_transfer = KnowledgeTransfer(f"Transfer_{pipeline_id}")
        
        # === é¢„è®­ç»ƒé…ç½® ===
        self.pretraining_config = {
            'upper_pretraining_episodes': config.pretraining_episodes // 3,
            'lower_pretraining_episodes': config.pretraining_episodes // 3,
            'joint_finetuning_episodes': config.pretraining_episodes // 3,
            'enable_curriculum_learning': True,
            'enable_knowledge_transfer': True,
            'progressive_difficulty': True,
            'early_stopping_patience': 50
        }
        
        # === é¢„è®­ç»ƒçŠ¶æ€ ===
        self.pretraining_state = {
            'current_stage': PretrainingStage.INITIALIZATION,
            'stage_episode': 0,
            'total_episode': 0,
            'stage_start_time': 0.0,
            'pipeline_start_time': 0.0,
            'is_pretraining': False
        }
        
        # === é¢„è®­ç»ƒå†å² ===
        self.pretraining_history: List[PretrainingMetrics] = []
        self.stage_performance_history: Dict[PretrainingStage, List[float]] = {
            stage: [] for stage in PretrainingStage
        }
        
        # === æ—¥å¿—è®¾ç½® ===
        self._setup_logging()
        
        # === ä¿å­˜è·¯å¾„ ===
        self.save_dir = f"checkpoints/pretraining/{pipeline_id}"
        os.makedirs(self.save_dir, exist_ok=True)
        
        print(f"âœ… é¢„è®­ç»ƒæµæ°´çº¿åˆå§‹åŒ–å®Œæˆ: {pipeline_id}")
        print(f"   é¢„è®­ç»ƒå›åˆ: ä¸Šå±‚={self.pretraining_config['upper_pretraining_episodes']}, "
              f"ä¸‹å±‚={self.pretraining_config['lower_pretraining_episodes']}, "
              f"è”åˆ={self.pretraining_config['joint_finetuning_episodes']}")
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_dir = f"logs/pretraining/{self.pipeline_id}"
        os.makedirs(log_dir, exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f"{log_dir}/pretraining_pipeline.log"),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger(f"PretrainingPipeline_{self.pipeline_id}")
    
    def run_pretraining(self) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„é¢„è®­ç»ƒæµæ°´çº¿
        
        Returns:
            é¢„è®­ç»ƒç»“æœç»Ÿè®¡
        """
        self.pretraining_state['is_pretraining'] = True
        self.pretraining_state['pipeline_start_time'] = time.time()
        
        self.logger.info("ğŸš€ å¼€å§‹é¢„è®­ç»ƒæµæ°´çº¿")
        
        try:
            # === é˜¶æ®µ1: ä¸Šå±‚é¢„è®­ç»ƒ ===
            self.logger.info("ğŸ“ˆ é˜¶æ®µ1: ä¸Šå±‚é¢„è®­ç»ƒ")
            upper_stats = self._run_upper_pretraining()
            
            # === é˜¶æ®µ2: ä¸‹å±‚é¢„è®­ç»ƒ ===
            self.logger.info("âš¡ é˜¶æ®µ2: ä¸‹å±‚é¢„è®­ç»ƒ")
            lower_stats = self._run_lower_pretraining()
            
            # === é˜¶æ®µ3: çŸ¥è¯†è¿ç§» ===
            self.logger.info("ğŸ”„ é˜¶æ®µ3: çŸ¥è¯†è¿ç§»")
            transfer_stats = self._run_knowledge_transfer()
            
            # === é˜¶æ®µ4: è”åˆå¾®è°ƒ ===
            self.logger.info("ğŸ¯ é˜¶æ®µ4: è”åˆå¾®è°ƒ")
            finetuning_stats = self._run_joint_finetuning()
            
            # === å®Œæˆé¢„è®­ç»ƒ ===
            self._complete_pretraining()
            
            # ç»¼åˆç»Ÿè®¡
            pipeline_stats = self._calculate_pipeline_statistics(
                upper_stats, lower_stats, transfer_stats, finetuning_stats
            )
            
            self.logger.info("âœ… é¢„è®­ç»ƒæµæ°´çº¿å®Œæˆ")
            
            return pipeline_stats
            
        except Exception as e:
            self.logger.error(f"âŒ é¢„è®­ç»ƒæµæ°´çº¿å¤±è´¥: {str(e)}")
            raise
        finally:
            self.pretraining_state['is_pretraining'] = False
    
    def _run_upper_pretraining(self) -> Dict[str, Any]:
        """è¿è¡Œä¸Šå±‚é¢„è®­ç»ƒ"""
        self._enter_stage(PretrainingStage.UPPER_PRETRAINING)
        
        episodes = self.pretraining_config['upper_pretraining_episodes']
        self.logger.info(f"å¼€å§‹ä¸Šå±‚é¢„è®­ç»ƒ: {episodes} å›åˆ")
        
        # é…ç½®è¯¾ç¨‹å­¦ä¹ 
        if self.pretraining_config['enable_curriculum_learning']:
            self._configure_upper_curriculum()
        
        # æ‰§è¡Œä¸Šå±‚é¢„è®­ç»ƒ
        upper_stats = {}
        for episode in range(episodes):
            self.pretraining_state['stage_episode'] = episode
            self.pretraining_state['total_episode'] += 1
            
            # è·å–å½“å‰éš¾åº¦
            if self.pretraining_config['progressive_difficulty']:
                difficulty = self.curriculum_learning.get_current_difficulty(episode, episodes)
                curriculum_params = self.curriculum_learning.generate_curriculum_parameters(difficulty)
                self._apply_upper_curriculum(curriculum_params)
            
            # è®­ç»ƒä¸€ä¸ªå›åˆï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            episode_metrics = self._simulate_upper_training_episode(episode)
            
            # è®°å½•æ€§èƒ½
            self.stage_performance_history[PretrainingStage.UPPER_PRETRAINING].append(
                episode_metrics.stage_performance
            )
            
            # æ£€æŸ¥æ—©åœ
            if self._should_early_stop_stage(PretrainingStage.UPPER_PRETRAINING):
                self.logger.info(f"ä¸Šå±‚é¢„è®­ç»ƒæ—©åœäºå›åˆ {episode}")
                break
            
            # å®šæœŸæ—¥å¿—
            if (episode + 1) % 20 == 0:
                self.logger.info(f"ä¸Šå±‚é¢„è®­ç»ƒè¿›åº¦: {episode+1}/{episodes}, "
                               f"æ€§èƒ½={episode_metrics.stage_performance:.3f}")
        
        # ä¿å­˜ä¸Šå±‚é¢„è®­ç»ƒæ¨¡å‹
        upper_checkpoint = self._save_stage_checkpoint(PretrainingStage.UPPER_PRETRAINING)
        
        upper_stats = {
            'episodes': episodes,
            'final_performance': self.stage_performance_history[PretrainingStage.UPPER_PRETRAINING][-1],
            'avg_performance': np.mean(self.stage_performance_history[PretrainingStage.UPPER_PRETRAINING]),
            'checkpoint_path': upper_checkpoint
        }
        
        self.logger.info(f"ä¸Šå±‚é¢„è®­ç»ƒå®Œæˆ: æœ€ç»ˆæ€§èƒ½={upper_stats['final_performance']:.3f}")
        
        return upper_stats
    
    def _run_lower_pretraining(self) -> Dict[str, Any]:
        """è¿è¡Œä¸‹å±‚é¢„è®­ç»ƒ"""
        self._enter_stage(PretrainingStage.LOWER_PRETRAINING)
        
        episodes = self.pretraining_config['lower_pretraining_episodes']
        self.logger.info(f"å¼€å§‹ä¸‹å±‚é¢„è®­ç»ƒ: {episodes} å›åˆ")
        
        # é…ç½®è¯¾ç¨‹å­¦ä¹ 
        if self.pretraining_config['enable_curriculum_learning']:
            self._configure_lower_curriculum()
        
        # æ‰§è¡Œä¸‹å±‚é¢„è®­ç»ƒ
        for episode in range(episodes):
            self.pretraining_state['stage_episode'] = episode
            self.pretraining_state['total_episode'] += 1
            
            # è·å–å½“å‰éš¾åº¦
            if self.pretraining_config['progressive_difficulty']:
                difficulty = self.curriculum_learning.get_current_difficulty(episode, episodes)
                curriculum_params = self.curriculum_learning.generate_curriculum_parameters(difficulty)
                self._apply_lower_curriculum(curriculum_params)
            
            # è®­ç»ƒä¸€ä¸ªå›åˆ
            episode_metrics = self._simulate_lower_training_episode(episode)
            
            # è®°å½•æ€§èƒ½
            self.stage_performance_history[PretrainingStage.LOWER_PRETRAINING].append(
                episode_metrics.stage_performance
            )
            
            # æ£€æŸ¥æ—©åœ
            if self._should_early_stop_stage(PretrainingStage.LOWER_PRETRAINING):
                self.logger.info(f"ä¸‹å±‚é¢„è®­ç»ƒæ—©åœäºå›åˆ {episode}")
                break
            
            # å®šæœŸæ—¥å¿—
            if (episode + 1) % 20 == 0:
                self.logger.info(f"ä¸‹å±‚é¢„è®­ç»ƒè¿›åº¦: {episode+1}/{episodes}, "
                               f"æ€§èƒ½={episode_metrics.stage_performance:.3f}")
        
        # ä¿å­˜ä¸‹å±‚é¢„è®­ç»ƒæ¨¡å‹
        lower_checkpoint = self._save_stage_checkpoint(PretrainingStage.LOWER_PRETRAINING)
        
        lower_stats = {
            'episodes': episodes,
            'final_performance': self.stage_performance_history[PretrainingStage.LOWER_PRETRAINING][-1],
            'avg_performance': np.mean(self.stage_performance_history[PretrainingStage.LOWER_PRETRAINING]),
            'checkpoint_path': lower_checkpoint
        }
        
        self.logger.info(f"ä¸‹å±‚é¢„è®­ç»ƒå®Œæˆ: æœ€ç»ˆæ€§èƒ½={lower_stats['final_performance']:.3f}")
        
        return lower_stats
    
    def _run_knowledge_transfer(self) -> Dict[str, Any]:
        """è¿è¡ŒçŸ¥è¯†è¿ç§»"""
        self._enter_stage(PretrainingStage.KNOWLEDGE_TRANSFER)
        
        self.logger.info("å¼€å§‹å±‚é—´çŸ¥è¯†è¿ç§»")
        
        transfer_stats = {
            'upper_to_lower': {},
            'lower_to_upper': {},
            'bidirectional_transfer': {}
        }
        
        if self.pretraining_config['enable_knowledge_transfer']:
            # ä¸Šå±‚åˆ°ä¸‹å±‚è¿ç§»
            self.logger.info("æ‰§è¡Œä¸Šå±‚â†’ä¸‹å±‚çŸ¥è¯†è¿ç§»")
            upper_to_lower = self.knowledge_transfer.transfer_upper_to_lower(
                self.upper_trainer.agent,
                self.lower_trainer.agent
            )
            transfer_stats['upper_to_lower'] = upper_to_lower
            
            # ä¸‹å±‚åˆ°ä¸Šå±‚è¿ç§»
            self.logger.info("æ‰§è¡Œä¸‹å±‚â†’ä¸Šå±‚çŸ¥è¯†è¿ç§»")
            lower_to_upper = self.knowledge_transfer.transfer_lower_to_upper(
                self.lower_trainer.agent,
                self.upper_trainer.agent
            )
            transfer_stats['lower_to_upper'] = lower_to_upper
            
            # è®¡ç®—åŒå‘è¿ç§»æ•ˆæœ
            bidirectional_score = (
                upper_to_lower['transfer_score'] + lower_to_upper['transfer_score']
            ) / 2
            
            transfer_stats['bidirectional_transfer'] = {
                'transfer_score': bidirectional_score,
                'transfer_success': bidirectional_score > 0.5,
                'total_transfer_time': (
                    upper_to_lower['transfer_time'] + lower_to_upper['transfer_time']
                )
            }
            
            self.logger.info(f"çŸ¥è¯†è¿ç§»å®Œæˆ: åŒå‘å¾—åˆ†={bidirectional_score:.3f}")
        else:
            self.logger.info("çŸ¥è¯†è¿ç§»å·²ç¦ç”¨")
        
        return transfer_stats
    
    def _run_joint_finetuning(self) -> Dict[str, Any]:
        """è¿è¡Œè”åˆå¾®è°ƒ"""
        self._enter_stage(PretrainingStage.JOINT_FINETUNING)
        
        episodes = self.pretraining_config['joint_finetuning_episodes']
        self.logger.info(f"å¼€å§‹è”åˆå¾®è°ƒ: {episodes} å›åˆ")
        
        # è”åˆå¾®è°ƒ
        for episode in range(episodes):
            self.pretraining_state['stage_episode'] = episode
            self.pretraining_state['total_episode'] += 1
            
            # è”åˆè®­ç»ƒä¸€ä¸ªå›åˆ
            episode_metrics = self._simulate_joint_training_episode(episode)
            
            # è®°å½•æ€§èƒ½
            self.stage_performance_history[PretrainingStage.JOINT_FINETUNING].append(
                episode_metrics.stage_performance
            )
            
            # æ£€æŸ¥æ—©åœ
            if self._should_early_stop_stage(PretrainingStage.JOINT_FINETUNING):
                self.logger.info(f"è”åˆå¾®è°ƒæ—©åœäºå›åˆ {episode}")
                break
            
            # å®šæœŸæ—¥å¿—
            if (episode + 1) % 10 == 0:
                self.logger.info(f"è”åˆå¾®è°ƒè¿›åº¦: {episode+1}/{episodes}, "
                               f"æ€§èƒ½={episode_metrics.stage_performance:.3f}")
        
        # ä¿å­˜è”åˆå¾®è°ƒæ¨¡å‹
        joint_checkpoint = self._save_stage_checkpoint(PretrainingStage.JOINT_FINETUNING)
        
        finetuning_stats = {
            'episodes': episodes,
            'final_performance': self.stage_performance_history[PretrainingStage.JOINT_FINETUNING][-1],
            'avg_performance': np.mean(self.stage_performance_history[PretrainingStage.JOINT_FINETUNING]),
            'checkpoint_path': joint_checkpoint
        }
        
        self.logger.info(f"è”åˆå¾®è°ƒå®Œæˆ: æœ€ç»ˆæ€§èƒ½={finetuning_stats['final_performance']:.3f}")
        
        return finetuning_stats
    
    def _simulate_upper_training_episode(self, episode: int) -> PretrainingMetrics:
        """æ¨¡æ‹Ÿä¸Šå±‚è®­ç»ƒå›åˆ"""
        # ç®€åŒ–çš„ä¸Šå±‚è®­ç»ƒæ¨¡æ‹Ÿ
        base_performance = 0.3 + episode * 0.01  # é€æ¸æå‡
        noise = np.random.normal(0, 0.05)  # æ·»åŠ å™ªå£°
        performance = max(0.0, min(1.0, base_performance + noise))
        
        metrics = PretrainingMetrics(
            stage=PretrainingStage.UPPER_PRETRAINING,
            stage_episode=episode,
            total_episode=self.pretraining_state['total_episode'],
            stage_performance=performance,
            stage_specific_metrics={
                'hypervolume': performance * 0.8,
                'pareto_front_size': int(10 + performance * 20),
                'soc_balance_score': performance * 0.9,
                'temp_balance_score': performance * 0.85
            }
        )
        
        self.pretraining_history.append(metrics)
        return metrics
    
    def _simulate_lower_training_episode(self, episode: int) -> PretrainingMetrics:
        """æ¨¡æ‹Ÿä¸‹å±‚è®­ç»ƒå›åˆ"""
        # ç®€åŒ–çš„ä¸‹å±‚è®­ç»ƒæ¨¡æ‹Ÿ
        base_performance = 0.4 + episode * 0.008  # é€æ¸æå‡
        noise = np.random.normal(0, 0.03)  # æ·»åŠ å™ªå£°
        performance = max(0.0, min(1.0, base_performance + noise))
        
        metrics = PretrainingMetrics(
            stage=PretrainingStage.LOWER_PRETRAINING,
            stage_episode=episode,
            total_episode=self.pretraining_state['total_episode'],
            stage_performance=performance,
            stage_specific_metrics={
                'tracking_accuracy': performance,
                'response_time': 0.05 * (1.0 - performance * 0.5),
                'constraint_satisfaction': performance * 0.95,
                'control_smoothness': performance * 0.9
            }
        )
        
        self.pretraining_history.append(metrics)
        return metrics
    
    def _simulate_joint_training_episode(self, episode: int) -> PretrainingMetrics:
        """æ¨¡æ‹Ÿè”åˆè®­ç»ƒå›åˆ"""
        # è”åˆè®­ç»ƒæ€§èƒ½ = ä¸Šå±‚æ€§èƒ½ * 0.5 + ä¸‹å±‚æ€§èƒ½ * 0.5
        upper_performance = 0.7 + episode * 0.005
        lower_performance = 0.8 + episode * 0.003
        joint_performance = (upper_performance + lower_performance) / 2
        
        noise = np.random.normal(0, 0.02)
        performance = max(0.0, min(1.0, joint_performance + noise))
        
        metrics = PretrainingMetrics(
            stage=PretrainingStage.JOINT_FINETUNING,
            stage_episode=episode,
            total_episode=self.pretraining_state['total_episode'],
            stage_performance=performance,
            stage_specific_metrics={
                'upper_contribution': upper_performance,
                'lower_contribution': lower_performance,
                'coordination_efficiency': performance * 0.9,
                'overall_stability': performance * 0.95
            }
        )
        
        self.pretraining_history.append(metrics)
        return metrics
    
    def _enter_stage(self, stage: PretrainingStage):
        """è¿›å…¥æ–°é˜¶æ®µ"""
        self.pretraining_state['current_stage'] = stage
        self.pretraining_state['stage_episode'] = 0
        self.pretraining_state['stage_start_time'] = time.time()
        
        self.logger.info(f"è¿›å…¥é¢„è®­ç»ƒé˜¶æ®µ: {stage.value}")
    
    def _configure_upper_curriculum(self):
        """é…ç½®ä¸Šå±‚è¯¾ç¨‹å­¦ä¹ """
        # é…ç½®ä¸Šå±‚ä¸“ç”¨çš„è¯¾ç¨‹å­¦ä¹ å‚æ•°
        self.curriculum_learning.curriculum_config.update({
            'initial_difficulty': 0.2,
            'final_difficulty': 0.9,
            'performance_threshold': 0.6
        })
    
    def _configure_lower_curriculum(self):
        """é…ç½®ä¸‹å±‚è¯¾ç¨‹å­¦ä¹ """
        # é…ç½®ä¸‹å±‚ä¸“ç”¨çš„è¯¾ç¨‹å­¦ä¹ å‚æ•°
        self.curriculum_learning.curriculum_config.update({
            'initial_difficulty': 0.3,
            'final_difficulty': 1.0,
            'performance_threshold': 0.7
        })
    
    def _apply_upper_curriculum(self, curriculum_params: Dict[str, Any]):
        """åº”ç”¨ä¸Šå±‚è¯¾ç¨‹å‚æ•°"""
        # åº”ç”¨è¯¾ç¨‹å‚æ•°åˆ°ä¸Šå±‚è®­ç»ƒå™¨
        self.logger.debug(f"åº”ç”¨ä¸Šå±‚è¯¾ç¨‹å‚æ•°: {curriculum_params}")
    
    def _apply_lower_curriculum(self, curriculum_params: Dict[str, Any]):
        """åº”ç”¨ä¸‹å±‚è¯¾ç¨‹å‚æ•°"""
        # åº”ç”¨è¯¾ç¨‹å‚æ•°åˆ°ä¸‹å±‚è®­ç»ƒå™¨
        self.logger.debug(f"åº”ç”¨ä¸‹å±‚è¯¾ç¨‹å‚æ•°: {curriculum_params}")
    
    def _should_early_stop_stage(self, stage: PretrainingStage) -> bool:
        """æ£€æŸ¥é˜¶æ®µæ˜¯å¦åº”è¯¥æ—©åœ"""
        performance_history = self.stage_performance_history[stage]
        
        if len(performance_history) < self.pretraining_config['early_stopping_patience']:
            return False
        
        # æ£€æŸ¥æœ€è¿‘çš„æ€§èƒ½æ˜¯å¦åœæ»
        recent_performance = performance_history[-self.pretraining_config['early_stopping_patience']:]
        
        # è®¡ç®—æ€§èƒ½æ”¹å–„
        first_half = np.mean(recent_performance[:len(recent_performance)//2])
        second_half = np.mean(recent_performance[len(recent_performance)//2:])
        
        improvement = (second_half - first_half) / max(abs(first_half), 1e-6)
        
        # å¦‚æœæ”¹å–„å°äº1%ï¼Œè®¤ä¸ºæ”¶æ•›
        return improvement < 0.01
    
    def _save_stage_checkpoint(self, stage: PretrainingStage) -> str:
        """ä¿å­˜é˜¶æ®µæ£€æŸ¥ç‚¹"""
        checkpoint_path = os.path.join(self.save_dir, f"{stage.value}_checkpoint.pth")
        
        checkpoint = {
            'stage': stage.value,
            'episode': self.pretraining_state['stage_episode'],
            'total_episode': self.pretraining_state['total_episode'],
            'upper_agent_state': self.upper_trainer.agent.state_dict(),
            'lower_agent_state': self.lower_trainer.agent.state_dict(),
            'stage_performance_history': self.stage_performance_history[stage],
            'curriculum_state': {
                'current_difficulty': self.curriculum_learning.current_difficulty,
                'performance_history': self.curriculum_learning.performance_history
            },
            'knowledge_transfer_history': self.knowledge_transfer.transfer_history,
            'config': self.config
        }
        
        torch.save(checkpoint, checkpoint_path)
        self.logger.info(f"é˜¶æ®µæ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
        
        return checkpoint_path
    
    def _complete_pretraining(self):
        """å®Œæˆé¢„è®­ç»ƒ"""
        self.pretraining_state['current_stage'] = PretrainingStage.COMPLETED
        
        # ä¿å­˜æœ€ç»ˆé¢„è®­ç»ƒæ¨¡å‹
        final_checkpoint = os.path.join(self.save_dir, "pretraining_final.pth")
        
        final_model = {
            'pipeline_id': self.pipeline_id,
            'completion_time': time.time(),
            'total_episodes': self.pretraining_state['total_episode'],
            'final_upper_state': self.upper_trainer.agent.state_dict(),
            'final_lower_state': self.lower_trainer.agent.state_dict(),
            'pretraining_history': [
                {
                    'stage': m.stage.value,
                    'episode': m.total_episode,
                    'performance': m.stage_performance,
                    'stage_specific': m.stage_specific_metrics
                } for m in self.pretraining_history
            ],
            'stage_statistics': self._calculate_stage_statistics(),
            'config': self.config
        }
        
        torch.save(final_model, final_checkpoint)
        
        # ä¿å­˜é¢„è®­ç»ƒå†å²
        history_path = os.path.join(self.save_dir, "pretraining_history.json")
        with open(history_path, 'w') as f:
            json.dump(final_model['pretraining_history'], f, indent=2)
        
        self.logger.info(f"é¢„è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_checkpoint}")
    
    def _calculate_stage_statistics(self) -> Dict[str, Any]:
        """è®¡ç®—é˜¶æ®µç»Ÿè®¡"""
        stage_stats = {}
        
        for stage in PretrainingStage:
            if stage in self.stage_performance_history:
                performance_list = self.stage_performance_history[stage]
                if performance_list:
                    stage_stats[stage.value] = {
                        'episodes': len(performance_list),
                        'initial_performance': performance_list[0],
                        'final_performance': performance_list[-1],
                        'max_performance': max(performance_list),
                        'avg_performance': np.mean(performance_list),
                        'performance_improvement': performance_list[-1] - performance_list[0],
                        'convergence_episode': self._find_convergence_episode(performance_list)
                    }
        
        return stage_stats
    
    def _find_convergence_episode(self, performance_list: List[float]) -> int:
        """æ‰¾åˆ°æ”¶æ•›å›åˆ"""
        if len(performance_list) < 20:
            return -1
        
        # ç®€åŒ–çš„æ”¶æ•›æ£€æµ‹
        window_size = 10
        for i in range(window_size, len(performance_list)):
            window = performance_list[i-window_size:i]
            if np.std(window) < 0.02:  # æ ‡å‡†å·®å°äº2%
                return i - window_size
        
        return -1
    
    def _calculate_pipeline_statistics(self,
                                     upper_stats: Dict,
                                     lower_stats: Dict,
                                     transfer_stats: Dict,
                                     finetuning_stats: Dict) -> Dict[str, Any]:
        """è®¡ç®—æµæ°´çº¿ç»Ÿè®¡"""
        total_time = time.time() - self.pretraining_state['pipeline_start_time']
        
        pipeline_stats = {
            'pipeline_summary': {
                'pipeline_id': self.pipeline_id,
                'total_time': total_time,
                'total_episodes': self.pretraining_state['total_episode'],
                'stages_completed': len([s for s in self.stage_performance_history.values() if s])
            },
            
            'stage_results': {
                'upper_pretraining': upper_stats,
                'lower_pretraining': lower_stats,
                'knowledge_transfer': transfer_stats,
                'joint_finetuning': finetuning_stats
            },
            
            'overall_performance': {
                'final_upper_performance': upper_stats.get('final_performance', 0.0),
                'final_lower_performance': lower_stats.get('final_performance', 0.0),
                'final_joint_performance': finetuning_stats.get('final_performance', 0.0),
                'transfer_success_rate': (
                    transfer_stats.get('bidirectional_transfer', {}).get('transfer_success', False)
                ),
                'overall_improvement': self._calculate_overall_improvement()
            },
            
            'curriculum_learning': {
                'final_difficulty': self.curriculum_learning.current_difficulty,
                'difficulty_progression': self.curriculum_learning.curriculum_config['difficulty_progression'],
                'performance_history_length': len(self.curriculum_learning.performance_history)
            },
            
            'efficiency_metrics': {
                'episodes_per_hour': self.pretraining_state['total_episode'] / (total_time / 3600),
                'convergence_efficiency': self._calculate_convergence_efficiency(),
                'knowledge_transfer_efficiency': transfer_stats.get('bidirectional_transfer', {}).get('transfer_score', 0.0)
            }
        }
        
        return pipeline_stats
    
    def _calculate_overall_improvement(self) -> float:
        """è®¡ç®—æ•´ä½“æ”¹å–„"""
        if not self.pretraining_history:
            return 0.0
        
        # æ¯”è¾ƒç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªé˜¶æ®µçš„æ€§èƒ½
        first_performance = self.pretraining_history[0].stage_performance
        last_performance = self.pretraining_history[-1].stage_performance
        
        improvement = (last_performance - first_performance) / max(abs(first_performance), 1e-6)
        return improvement
    
    def _calculate_convergence_efficiency(self) -> float:
        """è®¡ç®—æ”¶æ•›æ•ˆç‡"""
        stage_stats = self._calculate_stage_statistics()
        
        convergence_episodes = []
        for stage_stat in stage_stats.values():
            if stage_stat['convergence_episode'] > 0:
                convergence_episodes.append(stage_stat['convergence_episode'])
        
        if convergence_episodes:
            avg_convergence = np.mean(convergence_episodes)
            # æ•ˆç‡ = 1 / å¹³å‡æ”¶æ•›å›åˆæ•°ï¼ˆå½’ä¸€åŒ–ï¼‰
            efficiency = 1.0 / (1.0 + avg_convergence / 100.0)
            return efficiency
        
        return 0.5  # é»˜è®¤æ•ˆç‡
    
    def load_stage_checkpoint(self, stage: PretrainingStage, checkpoint_path: str) -> bool:
        """åŠ è½½é˜¶æ®µæ£€æŸ¥ç‚¹"""
        try:
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            
            # åŠ è½½æ™ºèƒ½ä½“çŠ¶æ€
            if 'upper_agent_state' in checkpoint:
                self.upper_trainer.agent.load_state_dict(checkpoint['upper_agent_state'])
            
            if 'lower_agent_state' in checkpoint:
                self.lower_trainer.agent.load_state_dict(checkpoint['lower_agent_state'])
            
            # åŠ è½½è¯¾ç¨‹å­¦ä¹ çŠ¶æ€
            if 'curriculum_state' in checkpoint:
                curriculum_state = checkpoint['curriculum_state']
                self.curriculum_learning.current_difficulty = curriculum_state['current_difficulty']
                self.curriculum_learning.performance_history = curriculum_state['performance_history']
            
            # åŠ è½½çŸ¥è¯†è¿ç§»å†å²
            if 'knowledge_transfer_history' in checkpoint:
                self.knowledge_transfer.transfer_history = checkpoint['knowledge_transfer_history']
            
            # åŠ è½½æ€§èƒ½å†å²
            if 'stage_performance_history' in checkpoint:
                self.stage_performance_history[stage] = checkpoint['stage_performance_history']
            
            self.logger.info(f"é˜¶æ®µæ£€æŸ¥ç‚¹åŠ è½½æˆåŠŸ: {checkpoint_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"é˜¶æ®µæ£€æŸ¥ç‚¹åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    def get_pretraining_status(self) -> Dict[str, Any]:
        """è·å–é¢„è®­ç»ƒçŠ¶æ€"""
        return {
            'pipeline_id': self.pipeline_id,
            'pretraining_state': self.pretraining_state.copy(),
            'current_stage': self.pretraining_state['current_stage'].value,
            'stage_progress': {
                stage.value: len(history) for stage, history in self.stage_performance_history.items()
            },
            'curriculum_status': {
                'current_difficulty': self.curriculum_learning.current_difficulty,
                'progression_type': self.curriculum_learning.curriculum_config['difficulty_progression']
            },
            'recent_performance': (
                self.pretraining_history[-5:] if len(self.pretraining_history) >= 5 
                else self.pretraining_history
            )
        }
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (f"PretrainingPipeline({self.pipeline_id}): "
                f"é˜¶æ®µ={self.pretraining_state['current_stage'].value}, "
                f"æ€»å›åˆ={self.pretraining_state['total_episode']}, "
                f"è¿è¡Œä¸­={self.pretraining_state['is_pretraining']}")
